"""Structured Planner for X-Agent.

Generates structured plans with skill bindings and tool constraints.
"""

# Use relative imports within the orchestrator package
from .models.plan import (
    StructuredPlan,
    PlanStep,
    Milestone,
    ToolConstraints,
    StepValidation,
)
from ..services.llm.router import LLMRouter
from ..services.skill_registry import SkillRegistry
from ..utils.logger import get_logger

logger = get_logger(__name__)


class StructuredPlanner:
    """ç”Ÿæˆç»“æ„åŒ–è®¡åˆ’ v2.0
    
    å…³é”®ç‰¹æ€§ï¼š
    - æŠ€èƒ½ç»‘å®šï¼šå°†è®¡åˆ’ä¸å…·ä½“æŠ€èƒ½å…³è”
    - å·¥å…·çº¦æŸï¼šç™½åå•/é»‘åå•æœºåˆ¶
    - æ­¥éª¤éªŒè¯ï¼šæ¯ä¸ªæ­¥éª¤éƒ½æœ‰éªŒè¯è§„åˆ™
    - é‡Œç¨‹ç¢‘æ£€æŸ¥ï¼šå…³é”®èŠ‚ç‚¹è‡ªåŠ¨éªŒè¯
    """
    
    # ä»»åŠ¡ç±»å‹è¯†åˆ«è§„åˆ™
    TASK_TYPE_RULES = {
        "research": {
            "allowed": ["web_search", "fetch_web_content", "memory"],
            "forbidden": ["pdf", "pptx", "run_in_terminal"],
            "keywords": ["ç ”ç©¶", "åˆ†æ", "è°ƒæŸ¥", "è¶‹åŠ¿", "ç°çŠ¶", "é¢„æµ‹", "å‘å±•", "è°ƒç ”"],
            "required_skills": [],
            "validation": "internal"
        },
        "creation": {
            "keywords": ["ç”Ÿæˆ", "åˆ›å»º", "æ’°å†™", "åˆ¶ä½œ", "ç¼–å†™", "è¾“å‡º", "åˆ›ä½œ"],
            "required_skills": ["write_file"],
            "forbidden": [],
            "validation": "internal",
            "implementation": "æ ¹æ®äº§ç‰©ç±»å‹é€‰æ‹© pdf/pptx/write_file",
            "default_allowed": ["web_search", "write_file", "run_in_terminal"]  # ğŸ”¥ FIX: Add default allowed tools
        },
        "pdf_creation": {
            "keywords": ["pdf", "PDF"],
            "allowed": [
                "run_in_terminal: python create_pdf_from_md.py",
                "write_file"
            ],  # ğŸ”¥ åªå…è®¸å¢å¼ºç‰ˆè„šæœ¬
            "forbidden": [],
            "required_skills": ["write_file", "run_in_terminal"],
            "implementation": "Python + reportlab (ä½¿ç”¨æŠ€èƒ½è„šæœ¬ create_pdf_from_md.py)",
            "system_prompt_rule": "pdf_skill_guidelines",
            "skill_scripts": [  # ğŸ”¥ NEW: æ˜ç¡®æŒ‡å®šæŠ€èƒ½è„šæœ¬è·¯å¾„
                "/workspace/x-agent/backend/src/skills/pdf/scripts/create_pdf_from_md.py"
            ]
        },
        "pptx_creation": {
            "keywords": ["ppt", "PPT", "æ¼”ç¤ºæ–‡ç¨¿", "å¹»ç¯ç‰‡"],
            "allowed": [
                "run_in_terminal: node create_presentation.js",
                "write_file"
            ],  # ğŸ”¥ å…·ä½“æŠ€èƒ½è„šæœ¬
            "forbidden": [],
            "required_skills": ["write_file", "run_in_terminal"],
            "implementation": "Node.js + PptxGenJS (ä½¿ç”¨æŠ€èƒ½è„šæœ¬)",
            "system_prompt_rule": "pptx_skill_guidelines",
            "skill_scripts": [  # ğŸ”¥ NEW: æ˜ç¡®æŒ‡å®šæŠ€èƒ½è„šæœ¬è·¯å¾„
                "/workspace/x-agent/backend/src/skills/pptx/scripts/create_presentation.js"
            ]
        },
        "data_processing": {
            "allowed": ["read_file", "write_file", "run_in_terminal"],
            "forbidden": ["web_search"],
            "keywords": ["è½¬æ¢", "å¤„ç†", "åˆ†æ", "ç»Ÿè®¡", "è®¡ç®—", "æ ¼å¼åŒ–", "æå–"],
            "required_skills": [],
            "validation": "automatic"
        },
        "web_task": {
            "allowed": ["web_search", "fetch_web_content", "browser_use"],
            "forbidden": ["pdf", "pptx"],
            "keywords": ["ç½‘é¡µ", "ç½‘ç«™", "åœ¨çº¿", "æœç´¢", "æŠ“å–", "æµè§ˆ"],
            "required_skills": [],
            "validation": "internal"
        },
        "code_development": {
            "allowed": ["read_file", "write_file", "run_in_terminal"],
            "forbidden": ["web_search", "pdf", "pptx"],
            "keywords": ["ä»£ç ", "ç¼–ç¨‹", "å¼€å‘", "è°ƒè¯•", "æµ‹è¯•", "é‡æ„"],
            "required_skills": [],
            "validation": "automatic"
        }
    }
    
    SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªç»“æ„åŒ–ä»»åŠ¡è§„åˆ’ä¸“å®¶ã€‚åˆ†æç”¨æˆ·çš„ç›®æ ‡ï¼Œç”Ÿæˆç»“æ„åŒ–çš„æ‰§è¡Œè®¡åˆ’ã€‚

## å¯ç”¨æŠ€èƒ½ä¿¡æ¯
{skill_info}

## å¯ç”¨å·¥å…·åˆ—è¡¨
{tools}

## âš ï¸ æ ¸å¿ƒåŸåˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰

### 1. YAGNI åŸåˆ™ - ç¦æ­¢çº¯éªŒè¯æ­¥éª¤
- æ¯ä¸ª step å¿…é¡»ç›´æ¥è´¡çŒ®äº goal
- ç¦æ­¢ç‹¬ç«‹çš„éªŒè¯æ­¥éª¤ï¼ˆå¦‚"list_dir: éªŒè¯ PDF æ˜¯å¦ç”Ÿæˆ"ï¼‰
- éªŒè¯åº”å†…å»ºåˆ° step ä¸­ï¼ˆå¦‚"è„šæœ¬æ‰§è¡ŒæˆåŠŸå³éªŒè¯é€šè¿‡"ï¼‰
- If not called, remove it

### 2. æœ€çŸ­è·¯å¾„åŸåˆ™
- ç”¨æœ€å°‘æ­¥éª¤å®Œæˆ goal
- ç›¸ä¼¼æ“ä½œå¿…é¡»åˆå¹¶ï¼ˆå¦‚è¿ç»­ write_file åº”è¯¥åˆå¹¶ä¸ºä¸€ä¸ªæ­¥éª¤ï¼‰
- ç›®æ ‡ï¼šæœ€å°å¿…è¦æ­¥éª¤æ•°ï¼ˆé€šå¸¸ 3-4 æ­¥ï¼‰

### 3. å·¥å…·è¯­ä¹‰æ¸…æ™°
- ä½¿ç”¨çœŸå®å·¥å…·åï¼šweb_search, write_file, run_in_terminal
- ç¦æ­¢è™šæ„å·¥å…·ï¼špdf_create åº”åˆ†è§£ä¸º "write_file + run_in_terminal"
- æ˜ç¡®å®ç°æ–¹å¼ï¼šå¦‚"Python + reportlab"æˆ–"Node.js + PptxGenJS"

### 4. ğŸ”¥ æŠ€èƒ½è„šæœ¬ä¼˜å…ˆåŸåˆ™ï¼ˆCRITICALï¼‰
- **å¦‚æœä»»åŠ¡ç»‘å®šäº†æŠ€èƒ½ï¼ˆå¦‚ pdf skillï¼‰ï¼Œå¿…é¡»ä½¿ç”¨è¯¥æŠ€èƒ½çš„è„šæœ¬ï¼**
- **PDF ç”Ÿæˆç¤ºä¾‹**:
  - âœ… æ­£ç¡®ï¼š`python create_pdf_from_md.py output.pdf input.md "æ ‡é¢˜"`
  - âŒ é”™è¯¯ï¼š`python convert_md_to_pdf.py ...`ï¼ˆè„šæœ¬ä¸å­˜åœ¨ï¼‰æˆ– `python create_simple_pdf.py ...`ï¼ˆå·²è¿‡æ—¶ï¼‰
- **åŸå› **ï¼š`create_pdf_from_md.py` å·²å¤„ç†äº†å­—ä½“æ³¨å†Œã€å¤šé¡µæ”¯æŒã€è‡ªåŠ¨æ’ç‰ˆç­‰å¤æ‚é€»è¾‘
- **æ£€æŸ¥æ¸…å•**ï¼š
  1. PDF skill â†’ **å”¯ä¸€æŒ‡å®š**ä½¿ç”¨ `create_pdf_from_md.py`
  2. ä¸è¦é‡æ–°å‘æ˜è½®å­ï¼

### 5. ğŸ”¥ğŸ”¥ğŸ”¥ ç ”ç©¶ + åˆ›ä½œç±»ä»»åŠ¡çš„ç‰¹æ®Šè§„åˆ™ï¼ˆCRITICAL FOR MIXED TASKSï¼‰
- **é€‚ç”¨åœºæ™¯**ï¼šä»»åŠ¡åŒæ—¶åŒ…å«â€œç ”ç©¶/åˆ†æâ€å’Œâ€œç”Ÿæˆ PDF/PPT/æ–‡æ¡£â€éœ€æ±‚
- **ç¤ºä¾‹**ï¼šâ€œæ·±åº¦ç ”ç©¶ 2026 AI è¶‹åŠ¿å¹¶ç”Ÿæˆ PDF æŠ¥å‘Šâ€
- **å¿…é¡»éµå®ˆçš„çº¦æŸ**ï¼š
  - âœ… **Step 1ï¼ˆä¿¡æ¯æ”¶é›†ï¼‰**: å¯ä»¥ä½¿ç”¨ `web_search`ï¼Œä½†ä»…é™ **1 æ¬¡**
  - âœ… **Step 2ï¼ˆå†…å®¹æ’°å†™ï¼‰**: ä½¿ç”¨ `write_file` æ•´ç†å’Œæ’°å†™å®Œæ•´çš„ MD æ ¼å¼æŠ¥å‘Š
  - âœ… **Step 3ï¼ˆæ ¼å¼è½¬æ¢ï¼‰**: 
    - **ä½¿ç”¨å¢å¼ºçš„ PDF è„šæœ¬ `create_pdf_from_md.py`**
    - **ç›´æ¥ä¼ å…¥ MD æ–‡ä»¶è·¯å¾„ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨è¯»å–å¹¶è½¬æ¢**
    - **å‘½ä»¤æ ¼å¼**: `python create_pdf_from_md.py output.pdf input.md "æ ‡é¢˜"`
  - âŒ **ç¦æ­¢**: åœ¨ Step 2 åŠä¹‹åç»§ç»­ä½¿ç”¨ `web_search`
  - âŒ **ç¦æ­¢**: åœ¨æœ€åä¸€æ­¥ä¹‹å‰ä½¿ç”¨ PDF ç”Ÿæˆå·¥å…·
  - âŒ **ç¦æ­¢**: ä½¿ç”¨æ—§ç‰ˆ `create_simple_pdf.py`ï¼ˆä»…æ”¯æŒç®€å•æ–‡æœ¬è¡Œï¼‰
- **æ­¥éª¤æ•°é‡**: ä¸¥æ ¼é™åˆ¶ä¸º **3 æ­¥**ï¼ˆé™¤éæœ‰ç‰¹æ®Šéœ€æ±‚ï¼‰
- **PDF å†…å®¹è¦æ±‚**: 
  - âœ… **å¿…é¡»åŒ…å«å®Œæ•´æŠ¥å‘Šå†…å®¹**ï¼ˆè„šæœ¬ä¼šè‡ªåŠ¨ä» MD æ–‡ä»¶è¯»å–ï¼‰
  - âœ… **æ”¯æŒå¤šé¡µã€ç« èŠ‚æ ¼å¼åŒ–ã€è‡ªåŠ¨åˆ†é¡µ**
  - âœ… **ä¸­æ–‡å­—ä½“æ”¯æŒ**ï¼ˆPingFang/STHeitiï¼‰
- **å·¥å…·çº¦æŸå»ºè®®**: 
  ```json
  {{
    "allowed": ["web_search", "write_file", "run_in_terminal"],
    "forbidden": [],
    "metadata": {{
      "web_search_max_iterations": 1,
      "web_search_allowed_steps": [1],
      "final_step_must_use_skill": true
    }}
  }}
  ```

## é‡è¦è§„åˆ™

1. å¿…é¡»ä¸ºæ¯ä¸ªæ­¥éª¤æŒ‡å®šæ˜ç¡®çš„å·¥å…·
2. æ ¹æ®ä»»åŠ¡ç±»å‹ä½¿ç”¨å¯¹åº”çš„å·¥å…·çº¦æŸï¼š
   - ç ”ç©¶æŠ¥å‘Šç±»ï¼šåªèƒ½ä½¿ç”¨ web_search, fetch_web_content, memory
   - åˆ›ä½œç”Ÿæˆç±»ï¼šå¿…é¡»åŒ…å« pdf/pptx/write_file ç­‰ç”Ÿæˆå·¥å…·
   - æ•°æ®å¤„ç†ç±»ï¼šä½¿ç”¨ read_file, write_file, run_in_terminal
   - PDF ç”Ÿæˆï¼šå¿…é¡»ä½¿ç”¨ Python + reportlabï¼Œç¦æ­¢ Node.js PDFKit
   - PPT ç”Ÿæˆï¼šå¿…é¡»ä½¿ç”¨ Node.js + PptxGenJS
3. æœ€åä¸€æ­¥é€šå¸¸æ˜¯ç”Ÿæˆ/è¾“å‡ºå·¥å…·ï¼ˆå¦‚ pdf, pptx, write_fileï¼‰
4. ç¦æ­¢åœ¨æ—©æœŸæ­¥éª¤ä½¿ç”¨æœ€ç»ˆç”Ÿæˆå·¥å…·
5. å¦‚æœä»»åŠ¡éœ€è¦å¤šæ­¥éª¤ç ”ç©¶ï¼Œé™åˆ¶ web_search ä½¿ç”¨æ¬¡æ•°ï¼ˆå»ºè®®â‰¤3 æ¬¡ï¼‰
6. éªŒè¯å†…å»ºï¼šæ¯ä¸ª step çš„ expected_output åº”åŒ…å«éªŒè¯æ ‡å‡†

## è¾“å‡ºè¦æ±‚

1. å¦‚æœç”¨æˆ·ä½¿ç”¨äº† /command æ ¼å¼ï¼ˆå¦‚ /pdfï¼‰ï¼Œå¿…é¡»ï¼š
   - å°†è¯¥æŠ€èƒ½åç§°å¡«å…¥ skill_binding å­—æ®µ
   - ä»æŠ€èƒ½çš„ allowed_tools ä¸­æå–å·¥å…·ç™½åå•
   - ç”Ÿæˆå¯¹åº”çš„ skill_command
   
2. æ¯ä¸ªæ­¥éª¤å¿…é¡»åŒ…å«ï¼š
   - id: å”¯ä¸€æ ‡è¯†ï¼ˆå¦‚ step_1, step_2ï¼‰
   - name: ç®€æ´çš„ä¸­æ–‡æè¿°
   - tool: ä½¿ç”¨çš„å·¥å…·åç§°ï¼ˆå¿…é¡»æ˜¯çœŸå®å·¥å…·ï¼‰
   - description: è¯¦ç»†è¯´æ˜ï¼ŒåŒ…æ‹¬å¦‚ä½•å®ç°å’ŒéªŒè¯
   - expected_output: é¢„æœŸè¾“å‡ºæè¿°

3. å¦‚æœå¯èƒ½ï¼Œä¸ºå…³é”®æ­¥éª¤æ·»åŠ ï¼š
   - skill_command: å…·ä½“çš„ CLI å‘½ä»¤
   - validation: éªŒè¯è§„åˆ™

4. ä¸ºå…³é”®èŠ‚ç‚¹å®šä¹‰ milestones

## ç¤ºä¾‹å¯¹æ¯”

âŒ é”™è¯¯ç¤ºä¾‹ï¼ˆ5 æ­¥ï¼ŒåŒ…å«è¿‡åº¦éªŒè¯ï¼‰:
{{
  "steps": [
    {{"id": "step_1", "name": "æœç´¢ä¿¡æ¯", "tool": "web_search"}},
    {{"id": "step_2", "name": "æ•´ç†èµ„æ–™", "tool": "write_file"}},
    {{"id": "step_3", "name": "æ’°å†™æ–‡ç« ", "tool": "write_file"}},
    {{"id": "step_4", "name": "ç”Ÿæˆ PDF", "tool": "pdf_create"}},  // âŒ è™šæ„å·¥å…·
    {{"id": "step_5", "name": "éªŒè¯ PDF", "tool": "list_dir"}}  // âŒ çº¯éªŒè¯
  ]
}}

âœ… æ­£ç¡®ç¤ºä¾‹ï¼ˆ3 æ­¥ï¼Œæœ€çŸ­è·¯å¾„ï¼‰:
{{
  "version": "2.0",
  "goal": "ç”Ÿæˆ 2026 AI è¶‹åŠ¿æŠ¥å‘Š PDF",
  "skill_binding": null,
  "tool_constraints": {{
    "allowed": ["web_search", "write_file", "run_in_terminal"],
    "forbidden": []
  }},
  "steps": [
    {{
      "id": "step_1",
      "name": "æœç´¢"2026 AI å‘å±•è¶‹åŠ¿"ï¼Œæ”¶é›†å…³é”®ä¿¡æ¯",
      "tool": "web_search",
      "description": "ä½¿ç”¨ web_search æœç´¢ç›¸å…³ä¿¡æ¯",
      "expected_output": "è·å– 5-10 ä¸ªç›¸å…³æœç´¢ç»“æœ"
    }},
    {{
      "id": "step_2",
      "name": "æ•´åˆæœç´¢ç»“æœï¼Œæ’°å†™ç ”ç©¶æŠ¥å‘Š",
      "tool": "write_file",
      "description": "å°†æœç´¢ç»“æœæ•´ç†ä¸º MD æ ¼å¼æŠ¥å‘Š",
      "expected_output": "ç”Ÿæˆ MD æ ¼å¼çš„ç ”ç©¶æŠ¥å‘Šæ–‡ä»¶"
    }},
    {{
      "id": "step_3",
      "name": "è¯»å– MD æŠ¥å‘Šå¹¶è½¬æ¢ä¸º PDFï¼ˆå¢å¼ºç‰ˆï¼‰",
      "tool": "run_in_terminal",
      "description": "**é‡è¦**: ä½¿ç”¨å¢å¼ºçš„ PDF ç”Ÿæˆè„šæœ¬ `create_pdf_from_md.py`ï¼Œè¯¥è„šæœ¬ä¼šè‡ªåŠ¨è¯»å– MD æ–‡ä»¶å†…å®¹å¹¶ç”Ÿæˆå¤šé¡µ PDFã€‚å‘½ä»¤æ ¼å¼ï¼š`python create_pdf_from_md.py {{{{workspace_path}}}}/pdfs/output.pdf {{{{workspace_path}}}}/mds/report.md \"æ ‡é¢˜\"`ã€‚æ”¯æŒä¸­æ–‡ã€è‡ªåŠ¨åˆ†é¡µã€ç« èŠ‚æ ¼å¼åŒ–ã€‚",
      "expected_output": "PDF æ–‡ä»¶æˆåŠŸç”Ÿæˆï¼ŒåŒ…å«å®Œæ•´çš„æŠ¥å‘Šå†…å®¹ï¼Œä¸­æ–‡å­—ç¬¦æ­£å¸¸æ˜¾ç¤ºï¼Œè‡ªåŠ¨å¤„ç†åˆ†é¡µå’Œæ’ç‰ˆ",
      "skill_command": "python create_pdf_from_md.py {{{{workspace_path}}}}/pdfs/report.pdf {{{{workspace_path}}}}/mds/report.md \"2026 AI è¶‹åŠ¿æŠ¥å‘Š\""
    }}
  ],
  "milestones": [
    {{
      "name": "ä¿¡æ¯æ”¶é›†å®Œæˆ",
      "after_step": "step_1",
      "check_type": "tool_output"
    }},
    {{
      "name": "æŠ¥å‘Šæ’°å†™å®Œæˆ",
      "after_step": "step_2",
      "check_type": "file_exists"
    }},
    {{
      "name": "PDF ç”Ÿæˆå®Œæˆ",
      "after_step": "step_3",
      "check_type": "file_exists"
    }}
  ]
}}

## ç¤ºä¾‹è¾“å…¥
"/pdf convert document.pdf to word"

## ç¤ºä¾‹è¾“å‡ºï¼ˆJSON æ ¼å¼ï¼‰
{{
  "version": "2.0",
  "goal": "å°† PDF æ–‡æ¡£è½¬æ¢ä¸º Word æ ¼å¼",
  "skill_binding": "pdf",
  "tool_constraints": {{
    "allowed": ["run_in_terminal", "read_file"],
    "forbidden": ["web_search"]
  }},
  "steps": [
    {{
      "id": "step_1",
      "name": "è¯»å– PDF æ–‡ä»¶",
      "tool": "read_file",
      "expected_output": "PDF æ–‡ä»¶å†…å®¹å·²åŠ è½½"
    }},
    {{
      "id": "step_2",
      "name": "è½¬æ¢æ–‡ä»¶æ ¼å¼",
      "skill_command": "pdftotext input.pdf output.docx",
      "tool": "run_in_terminal",
      "expected_output": "Word æ ¼å¼æ–‡ä»¶å·²ç”Ÿæˆ"
    }}
  ],
  "milestones": [
    {{
      "name": "PDF å·²è¯»å–",
      "after_step": "step_1",
      "check_type": "tool_output"
    }},
    {{
      "name": "è½¬æ¢å·²å®Œæˆ",
      "after_step": "step_2",
      "check_type": "file_exists"
    }}
  ]
}}

**ç›´æ¥è¾“å‡º JSONï¼Œä¸è¦æœ‰å…¶ä»–è¯´æ˜æ–‡å­—ã€‚**"""

    def __init__(self, llm_router: LLMRouter, skill_registry: SkillRegistry):
        """åˆå§‹åŒ–ç»“æ„åŒ–è§„åˆ’å™¨
        
        Args:
            llm_router: LLM è·¯ç”±å™¨å®ä¾‹
            skill_registry: æŠ€èƒ½æ³¨å†Œè¡¨å®ä¾‹
        """
        self.llm_router = llm_router
        self.skill_registry = skill_registry
        # ğŸ”¥ NEW: SKILL.md å†…å®¹ç¼“å­˜ï¼ˆé¿å…é‡å¤è¯»å–ï¼‰
        self._skill_md_cache: dict[str, str] = {}
        logger.info("StructuredPlanner initialized with progressive disclosure")
    
    def _extract_skill_guidance(self, skill_name: str, goal: str) -> str:
        """ä» SKILL.md ä¸­æå–å…³é”®æŒ‡å¼•ï¼ˆæ¸è¿›å¼æŠ«éœ²ï¼‰
        
        Args:
            skill_name: æŠ€èƒ½åç§°
            goal: ç”¨æˆ·ç›®æ ‡
            
        Returns:
            æå–çš„å…³é”®æŒ‡å¼•æ–‡æœ¬
        """
        import re
        from pathlib import Path
        
        # æ£€æŸ¥ç¼“å­˜
        if skill_name in self._skill_md_cache:
            skill_md_content = self._skill_md_cache[skill_name]
        else:
            # è¯»å– SKILL.md æ–‡ä»¶
            try:
                skill_dir = Path(__file__).parent.parent / 'skills' / skill_name
                skill_md_path = skill_dir / 'SKILL.md'
                
                if not skill_md_path.exists():
                    logger.warning(f"SKILL.md not found for skill: {skill_name}")
                    return ""
                
                skill_md_content = skill_md_path.read_text(encoding='utf-8')
                self._skill_md_cache[skill_name] = skill_md_content
                logger.info(
                    f"Loaded SKILL.md for {skill_name} ({len(skill_md_content)} chars)",
                    extra={"skill": skill_name}
                )
            except Exception as e:
                logger.error(f"Failed to read SKILL.md: {e}")
                return ""
        
        # ğŸ”¥ åŠ¨æ€æ¸è¿›å¼æŠ«éœ²ç­–ç•¥ï¼ˆåŸºäºæµç¨‹å›¾ï¼‰ï¼š
        # 1. Planner é˜¶æ®µï¼šæä¾› Skill åç§°å’Œæè¿°
        # 2. Router é˜¶æ®µï¼šæä¾›è¾“å…¥/è¾“å‡ºæ ¼å¼å’Œçº¦æŸ
        # 3. Task æ‰§è¡Œï¼šæä¾›ä¿¡ä¾‹å’Œè°ƒç”¨ç»†èŠ‚ï¼ˆå½“éœ€è¦æ—¶ï¼‰
        # 4. Reflection é˜¶æ®µï¼šè¡¥å……é™åˆ¶å’Œæç¤º
        
        guidance_parts = []
        
        # === Phase 1: Planner é˜¶æ®µ - æŠ€èƒ½åŸºæœ¬ä¿¡æ¯ ===
        phase1_guidance = self._extract_planner_guidance(skill_md_content, skill_name, goal)
        if phase1_guidance:
            guidance_parts.append(phase1_guidance)
        
        # === Phase 2: Router é˜¶æ®µ - è¾“å…¥è¾“å‡ºæ ¼å¼å’Œçº¦æŸ ===
        phase2_guidance = self._extract_router_guidance(skill_md_content, skill_name, goal)
        if phase2_guidance:
            guidance_parts.append(phase2_guidance)
        
        # === Phase 3: Task æ‰§è¡Œé˜¶æ®µ - ä¿¡ä¾‹å’Œè°ƒç”¨ç»†èŠ‚ ===
        phase3_guidance = self._extract_task_execution_guidance(skill_md_content, skill_name, goal)
        if phase3_guidance:
            guidance_parts.append(phase3_guidance)
        
        # === Phase 4: Reflection é˜¶æ®µ - é™åˆ¶å’Œæç¤º ===
        phase4_guidance = self._extract_reflection_guidance(skill_md_content, skill_name, goal)
        if phase4_guidance:
            guidance_parts.append(phase4_guidance)
        
        # è®°å½•æ—¥å¿—
        if guidance_parts:
            logger.info(
                "Extracted dynamic skill guidance (progressive disclosure)",
                extra={
                    "skill": skill_name,
                    "guidance_length": len("\n".join(guidance_parts)),
                    "phases_count": len([p for p in [phase1_guidance, phase2_guidance, phase3_guidance, phase4_guidance] if p]),
                }
            )
        
        return "\n".join(guidance_parts) if guidance_parts else ""
    
    def _auto_detect_skill_from_keywords(self, goal_lower: str) -> str | None:
        """é€šç”¨æŠ€èƒ½è‡ªåŠ¨å‘ç°æœºåˆ¶ï¼ˆåŸºäº SKILL.md ä¸­çš„ auto_trigger_keywordsï¼‰
        
        Args:
            goal_lower: ç”¨æˆ·ç›®æ ‡ï¼ˆå°å†™ï¼‰
            
        Returns:
            åŒ¹é…çš„æŠ€èƒ½åç§°ï¼Œå¦‚æœæ²¡æœ‰åŒ¹é…åˆ™è¿”å› None
        """
        # ğŸ”¥ é€šç”¨é€»è¾‘ï¼šéå†æ‰€æœ‰æŠ€èƒ½ï¼Œæ£€æŸ¥å®ƒä»¬çš„ auto_trigger_keywords
        skills = self.skill_registry.list_all_skills()
        
        for skill in skills:
            # ä»æŠ€èƒ½å…ƒæ•°æ®ä¸­è·å–è‡ªåŠ¨è§¦å‘å…³é”®è¯
            keywords = getattr(skill, 'keywords', []) or []
            
            # å¦‚æœæ²¡æœ‰å®šä¹‰ keywordsï¼Œä½¿ç”¨æŠ€èƒ½åç§°å’Œæè¿°ä½œä¸ºå¤‡é€‰
            if not keywords:
                keywords = [skill.name.lower()]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•å…³é”®è¯åŒ¹é…
            if any(kw.lower() in goal_lower for kw in keywords):
                logger.debug(
                    f"Skill auto-detected via keywords",
                    extra={
                        "skill": skill.name,
                        "matched_keywords": [kw for kw in keywords if kw.lower() in goal_lower],
                    }
                )
                return skill.name
        
        return None
    
    def _extract_planner_guidance(self, skill_md_content: str, skill_name: str, goal: str) -> str:
        """Phase 1: Planner é˜¶æ®µ - æä¾› Skill åç§°å’Œæè¿°
        
        ä» SKILL.md ä¸­æå–æŠ€èƒ½çš„åŸºæœ¬ä¿¡æ¯å’ŒåŠŸèƒ½æè¿°ã€‚
        """
        import re
        
        # å°è¯•æå–æŠ€èƒ½æ¦‚è¿°éƒ¨åˆ†
        overview_patterns = [
            r'^#\s*(.+?)\n',  # ä¸€çº§æ ‡é¢˜
            r'^##\s*Overview[\s\S]*?(?=^##|\Z)',  # Overview ç« èŠ‚
            r'^##\s*ç®€ä»‹[\s\S]*?(?=^##|\Z)',  # ç®€ä»‹ç« èŠ‚
            r'^##\s*Description[\s\S]*?(?=^##|\Z)',  # æè¿°ç« èŠ‚
        ]
        
        for pattern in overview_patterns:
            match = re.search(pattern, skill_md_content, re.MULTILINE | re.IGNORECASE)
            if match:
                content = match.group(0).strip()
                # é™åˆ¶é•¿åº¦åœ¨ 300 å­—ç¬¦ä»¥å†…
                if len(content) > 300:
                    content = content[:300] + "..."
                return f"\n\n## ğŸ“‹ æŠ€èƒ½æ¦‚è¿°\n{content}"
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ¦‚è¿°ï¼Œè¿”å›ç®€å•çš„æŠ€èƒ½åç§°
        return f"\n\n## ğŸ“‹ æŠ€èƒ½ï¼š{skill_name}"
    
    def _extract_router_guidance(self, skill_md_content: str, skill_name: str, goal: str) -> str:
        """Phase 2: Router é˜¶æ®µ - æä¾›è¾“å…¥/è¾“å‡ºæ ¼å¼å’Œçº¦æŸ
        
        ä» SKILL.md ä¸­æå–å·¥å…·çš„è¾“å…¥è¾“å‡ºæ ¼å¼ã€å…è®¸çš„å·¥å…·åˆ—è¡¨ç­‰çº¦æŸä¿¡æ¯ã€‚
        """
        import re
        
        guidance_parts = []
        
        # æŸ¥æ‰¾ Usage/Commands/CLI ç›¸å…³ç« èŠ‚
        usage_patterns = [
            (r'^##\s*Usage[\s\S]*?(?=^##|\Z)', "ä½¿ç”¨æ–¹æ³•"),
            (r'^##\s*Commands[\s\S]*?(?=^##|\Z)', "å‘½ä»¤"),
            (r'^##\s*CLI[\s\S]*?(?=^##|\Z)', "å‘½ä»¤è¡Œæ¥å£"),
            (r'^##\s*How to use[\s\S]*?(?=^##|\Z)', "å¦‚ä½•ä½¿ç”¨"),
        ]
        
        for pattern, title in usage_patterns:
            match = re.search(pattern, skill_md_content, re.MULTILINE | re.IGNORECASE)
            if match:
                content = match.group(0).strip()
                # æå–å…³é”®å‘½ä»¤æ ¼å¼ï¼ˆå‰ 500 å­—ç¬¦ï¼‰
                if len(content) > 500:
                    content = content[:500] + "..."
                guidance_parts.append(f"\n\n## ğŸ”§ {title}\n{content}")
                break
        
        # å¦‚æœæœ‰å¤šä¸ªéƒ¨åˆ†ï¼Œåªå–ç¬¬ä¸€ä¸ªåŒ¹é…çš„
        if guidance_parts:
            return "\n".join(guidance_parts)
        
        return ""
    
    def _extract_task_execution_guidance(self, skill_md_content: str, skill_name: str, goal: str) -> str:
        """Phase 3: Task æ‰§è¡Œé˜¶æ®µ - æä¾›ä¿¡ä¾‹å’Œè°ƒç”¨ç»†èŠ‚
        
        ä» SKILL.md ä¸­æå–å…·ä½“çš„ç¤ºä¾‹ã€æœ€ä½³å®è·µå’Œè°ƒç”¨ç»†èŠ‚ã€‚
        """
        import re
        
        guidance_parts = []
        
        # æŸ¥æ‰¾ Examples/Examples/Best Practices ç›¸å…³ç« èŠ‚
        example_patterns = [
            (r'^##\s*Examples[\s\S]*?(?=^##|\Z)', "ç¤ºä¾‹"),
            (r'^###\s*Example[\s\S]*?(?=^###|\Z)', "ç¤ºä¾‹"),
            (r'^##\s*Best Practices[\s\S]*?(?=^##|\Z)', "æœ€ä½³å®è·µ"),
        ]
        
        for pattern, title in example_patterns:
            match = re.search(pattern, skill_md_content, re.MULTILINE | re.IGNORECASE)
            if match:
                content = match.group(0).strip()
                # é™åˆ¶ç¤ºä¾‹é•¿åº¦åœ¨ 400 å­—ç¬¦
                if len(content) > 400:
                    content = content[:400] + "..."
                guidance_parts.append(f"\n\n## ğŸ“– {title}\n{content}")
                break
        
        if guidance_parts:
            return "\n".join(guidance_parts)
        
        return ""
    
    def _extract_reflection_guidance(self, skill_md_content: str, skill_name: str, goal: str) -> str:
        """Phase 4: Reflection é˜¶æ®µ - è¡¥å……é™åˆ¶å’Œæç¤º
        
        ä» SKILL.md ä¸­æå–æ³¨æ„äº‹é¡¹ã€é™åˆ¶æ¡ä»¶ã€å¸¸è§é”™è¯¯ç­‰åæ€ä¿¡æ¯ã€‚
        """
        import re
        
        guidance_parts = []
        
        # æŸ¥æ‰¾ Warnings/Caveats/Limitations/Tips ç›¸å…³ç« èŠ‚
        warning_patterns = [
            (r'^##\s*Warnings[\s\S]*?(?=^##|\Z)', "è­¦å‘Š"),
            (r'^##\s*Caveats[\s\S]*?(?=^##|\Z)', "æ³¨æ„äº‹é¡¹"),
            (r'^##\s*Limitations[\s\S]*?(?=^##|\Z)', "é™åˆ¶"),
            (r'^##\s*Troubleshooting[\s\S]*?(?=^##|\Z)', "æ•…éšœæ’é™¤"),
            (r'^##\s*Tips[\s\S]*?(?=^##|\Z)', "æç¤º"),
        ]
        
        for pattern, title in warning_patterns:
            match = re.search(pattern, skill_md_content, re.MULTILINE | re.IGNORECASE)
            if match:
                content = match.group(0).strip()
                # é™åˆ¶è­¦å‘Šä¿¡æ¯é•¿åº¦åœ¨ 300 å­—ç¬¦
                if len(content) > 300:
                    content = content[:300] + "..."
                guidance_parts.append(f"\n\n## âš ï¸ {title}\n{content}")
                break
        
        if guidance_parts:
            return "\n".join(guidance_parts)
        
        return ""
    
    def _detect_task_type(self, goal: str) -> tuple[str, dict]:
        """æ£€æµ‹ä»»åŠ¡ç±»å‹å¹¶è¿”å›å¯¹åº”çš„å·¥å…·çº¦æŸ
        
        Args:
            goal: ç”¨æˆ·ç›®æ ‡/ä»»åŠ¡æè¿°
            
        Returns:
            tuple[str, dict]: (ä¸»ä»»åŠ¡ç±»å‹åç§°ï¼Œå·¥å…·çº¦æŸå­—å…¸)
        """
        goal_lower = goal.lower()
        
        # ğŸ”¥ NEW: æ”¯æŒå¤šä»»åŠ¡ç±»å‹åˆå¹¶
        matched_types = []
        
        # éå†ä»»åŠ¡ç±»å‹è§„åˆ™ï¼Œæ‰¾åˆ°æ‰€æœ‰åŒ¹é…çš„ç±»å‹
        for task_type, rules in self.TASK_TYPE_RULES.items():
            keywords = rules["keywords"]
            match_count = sum(1 for kw in keywords if kw in goal_lower)
            
            # å¦‚æœåŒ¹é…åˆ°è‡³å°‘ä¸€ä¸ªå…³é”®è¯ï¼Œè®°å½•è¯¥ç±»å‹
            if match_count > 0:
                allowed = rules.get("allowed", rules.get("default_allowed", ["web_search", "write_file", "run_in_terminal"]))
                forbidden = rules.get("forbidden", [])
                
                matched_types.append({
                    "type": task_type,
                    "allowed": set(allowed),
                    "forbidden": set(forbidden),
                    "priority": len(rules.get("required_skills", [])),  # æœ‰ required_skills çš„ä¼˜å…ˆçº§æ›´é«˜
                })
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•ç±»å‹ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if not matched_types:
            logger.info("No specific task type detected, using default constraints")
            return "general", {
                "allowed": ["web_search", "fetch_web_content", "read_file", "write_file", "memory"],
                "forbidden": [],
            }
        
        # ğŸ”¥ NEW: åˆå¹¶å¤šä¸ªä»»åŠ¡ç±»å‹çš„å·¥å…·çº¦æŸ
        # ç­–ç•¥ï¼š
        # 1. å–æ‰€æœ‰ allowed çš„å¹¶é›†
        # 2. ä¿ç•™æ˜ç¡®çš„ forbiddenï¼ˆå³ä½¿å‡ºç°åœ¨å…¶ä»– allowed ä¸­ä¹Ÿè¦ä¿ç•™ï¼Œè¿™æ˜¯ç¡¬çº¦æŸï¼‰
        # 3. åªæœ‰å½“æŸä¸ªå·¥å…·åœ¨æ‰€æœ‰ç±»å‹ä¸­éƒ½æ˜¯ forbidden æ—¶ï¼Œæ‰åŠ å…¥æœ€ç»ˆ forbidden
        final_allowed = set()
        final_forbidden = set()
        
        # ä¼˜å…ˆå¤„ç†æœ‰é«˜ä¼˜å…ˆçº§çš„ç±»å‹ï¼ˆå¦‚ pdf_creation, pptx_creationï¼‰
        matched_types.sort(key=lambda x: x["priority"], reverse=True)
        
        # æ”¶é›†æ‰€æœ‰ç±»å‹çš„ forbidden ä¿¡æ¯
        all_forbidden_tools = {}  # tool -> count (è¢«å¤šå°‘ä¸ªç±»å‹ç¦æ­¢)
        
        for match in matched_types:
            final_allowed.update(match["allowed"])
            # ç»Ÿè®¡æ¯ä¸ªå·¥å…·è¢«ç¦æ­¢çš„æ¬¡æ•°
            for tool in match["forbidden"]:
                all_forbidden_tools[tool] = all_forbidden_tools.get(tool, 0) + 1
        
        # ğŸ”¥ FIX: åªæœ‰å½“å·¥å…·åœ¨æ‰€æœ‰åŒ¹é…çš„ç±»å‹ä¸­éƒ½è¢«ç¦æ­¢æ—¶ï¼Œæ‰åŠ å…¥æœ€ç»ˆ forbidden
        # è¿™æ ·å¯ä»¥ä¿ç•™æ˜ç¡®çš„ç¡¬çº¦æŸ
        num_matched_types = len(matched_types)
        for tool, count in all_forbidden_tools.items():
            # å¦‚æœè¯¥å·¥å…·åœ¨æ‰€æœ‰ç±»å‹ä¸­éƒ½è¢«ç¦æ­¢ï¼Œæˆ–è€…åœ¨é«˜ä¼˜å…ˆçº§ç±»å‹ä¸­è¢«ç¦æ­¢
            if count == num_matched_types or (
                num_matched_types > 1 and 
                all_forbidden_tools.get(tool, 0) >= num_matched_types - 1
            ):
                final_forbidden.add(tool)
        
        # ç§»é™¤å†²çªï¼šå¦‚æœä¸€ä¸ªå·¥å…·åŒæ—¶åœ¨ allowed å’Œ forbidden ä¸­ï¼Œä¼˜å…ˆ allowed
        final_allowed = final_allowed - final_forbidden
        
        primary_type = matched_types[0]["type"]
        
        logger.info(
            "Task type detected with merged constraints",
            extra={
                "primary_type": primary_type,
                "matched_types": [mt["type"] for mt in matched_types],
                "allowed_tools": list(final_allowed),
                "forbidden_tools": list(final_forbidden),
            }
        )
        
        return primary_type, {
            "allowed": list(final_allowed),
            "forbidden": list(final_forbidden),
        }
    
    async def generate(self, goal: str, skill_name: str | None = None, workspace_path: str | None = None) -> StructuredPlan:
        """ç”Ÿæˆç»“æ„åŒ–è®¡åˆ’
        
        Args:
            goal: ç”¨æˆ·ç›®æ ‡/ä»»åŠ¡æè¿°
            skill_name: æŒ‡å®šçš„æŠ€èƒ½åç§°ï¼ˆå¦‚æœæœ‰ï¼‰
            workspace_path: å·¥ä½œç›®å½•è·¯å¾„ï¼ˆç”¨äºæ–‡ä»¶è·¯å¾„æç¤ºï¼‰
            
        Returns:
            StructuredPlan: ç»“æ„åŒ–è®¡åˆ’å¯¹è±¡
        """
        logger.info(
            "Structured plan generation started",
            extra={
                "goal_length": len(goal),
                "skill_name": skill_name,
            }
        )
        
        # ğŸ”¥ NEW: æ£€æµ‹ PDF ç›¸å…³å…³é”®è¯ï¼Œå¼ºåˆ¶ç»‘å®š PDF skill
        goal_lower = goal.lower()
        
        # ğŸ”¥ CRITICAL FIX: ç§»é™¤æ‰€æœ‰ç¡¬ç¼–ç ï¼Œä½¿ç”¨é€šç”¨çš„æŠ€èƒ½è‡ªåŠ¨å‘ç°æœºåˆ¶
        # ä¸å†é’ˆå¯¹ç‰¹å®šæŠ€èƒ½å†™æ­»é€»è¾‘ï¼Œè€Œæ˜¯é€šè¿‡ SkillMetadata ä¸­çš„ auto_trigger_keywords
        if not skill_name:
            skill_name = self._auto_detect_skill_from_keywords(goal_lower)
            if skill_name:
                logger.info(
                    "Auto-detected skill from keywords",
                    extra={
                        "goal_preview": goal[:50],
                        "detected_skill": skill_name,
                    }
                )
        
        # è·å–æŠ€èƒ½ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        skill_info = ""
        tool_constraints = None
        
        if skill_name:
            skill = self.skill_registry.get_skill_metadata(skill_name)
            if skill:
                # ğŸ”¥ é€šç”¨å¤„ç†ï¼šä»æŠ€èƒ½å…ƒæ•°æ®ä¸­è·å–æ‰€æœ‰ä¿¡æ¯
                skill_info = f"- æŠ€èƒ½åç§°ï¼š{skill.name}\n- æŠ€èƒ½æè¿°ï¼š{skill.description}\n- å…è®¸çš„å·¥å…·ï¼š{skill.allowed_tools or 'æ— é™åˆ¶'}"
                
                # P1-2 NEW: å¼ºåˆ¶ä½¿ç”¨æŠ€èƒ½çš„ allowed_toolsï¼Œè€Œä¸æ˜¯è®© LLM å†³å®š
                if skill.allowed_tools:
                    # ğŸ”¥ é€šç”¨é€»è¾‘ï¼šç›´æ¥ä½¿ç”¨æŠ€èƒ½çš„ allowed_toolsï¼Œä¸å†ç‰¹æ®Šå¤„ç†æŸä¸ªæŠ€èƒ½
                    allowed_tools = list(skill.allowed_tools)
                    
                    tool_constraints = ToolConstraints(
                        allowed=allowed_tools,
                        forbidden=[t for t in ["web_search", "pdf", "pptx"] if t not in allowed_tools],
                        source="skill",  # âœ… æ ‡è®°ä¸ºæ¥è‡ªæŠ€èƒ½
                        priority=5,  # âœ… Skill çº¦æŸä¸­ç­‰ä¼˜å…ˆçº§
                    )
                    logger.info(
                        "Applied skill-based tool constraints (generic logic)",
                        extra={
                            "skill": skill.name,
                            "allowed": allowed_tools,
                            "forbidden": tool_constraints.forbidden,
                        }
                    )
        else:
            skill_info = "æ— ç‰¹å®šæŠ€èƒ½ç»‘å®š"
            
            # P3-1 NEW: å¦‚æœæ²¡æœ‰æŒ‡å®šæŠ€èƒ½ï¼Œæ ¹æ®ä»»åŠ¡ç±»å‹è‡ªåŠ¨ç”Ÿæˆå·¥å…·çº¦æŸ
            task_type, type_constraints = self._detect_task_type(goal)
            if tool_constraints is None and type_constraints:
                tool_constraints = ToolConstraints(
                    allowed=type_constraints["allowed"],
                    forbidden=type_constraints["forbidden"],
                    source="task_type",  # âœ… æ ‡è®°ä¸ºæ¥è‡ªä»»åŠ¡ç±»å‹æ£€æµ‹
                    priority=1,  # âœ… Task Type çº¦æŸä½ä¼˜å…ˆçº§
                )
                logger.info(
                    "Task-type-based tool constraints generated",
                    extra={
                        "task_type": task_type,
                        "allowed": type_constraints["allowed"],
                        "forbidden": type_constraints["forbidden"],
                    }
                )
        
        # ğŸ”¥ NEW: æ”¶é›†æŠ€èƒ½è„šæœ¬è·¯å¾„ï¼ˆå¦‚æœæœ‰ï¼‰
        skill_script_paths = []
        if skill_name:
            # ä»æŠ€èƒ½å…ƒæ•°æ®ä¸­è·å–è„šæœ¬è·¯å¾„
            try:
                from pathlib import Path
                skill_dir = Path(__file__).parent.parent / 'skills' / skill_name / 'scripts'
                if skill_dir.exists():
                    script_files = list(skill_dir.glob('*.py')) + list(skill_dir.glob('*.js'))
                    skill_script_paths = [str(f) for f in script_files]
                    logger.info(
                        "Skill scripts found",
                        extra={
                            "skill": skill_name,
                            "script_count": len(script_files),
                            "scripts": skill_script_paths,
                        }
                    )
            except Exception as e:
                logger.warning(f"Failed to get skill scripts: {e}")
        else:
            # ä»ä»»åŠ¡ç±»å‹è§„åˆ™ä¸­è·å–è„šæœ¬è·¯å¾„
            task_type, _ = self._detect_task_type(goal)
            if task_type in self.TASK_TYPE_RULES:
                skill_script_paths = self.TASK_TYPE_RULES[task_type].get('skill_scripts', [])
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ CRITICAL: æ¸è¿›å¼æŠ«éœ² - ä» SKILL.md ä¸­æå–å…³é”®æŒ‡å¼•
        skill_md_guidance = ""
        if skill_name:
            skill_md_guidance = self._extract_skill_guidance(skill_name, goal)
            if skill_md_guidance:
                logger.info(
                    "Extracted guidance from SKILL.md (progressive disclosure)",
                    extra={
                        "skill": skill_name,
                        "guidance_length": len(skill_md_guidance),
                    }
                )
        
        # æ„å»º prompt
        tools_list = list(set(tool_constraints.allowed)) if tool_constraints and tool_constraints.allowed else ["run_in_terminal", "read_file", "write_file", "web_search"]
        
        # ğŸ”¥ NEW: æ·»åŠ æŠ€èƒ½è„šæœ¬è·¯å¾„åˆ° skill_info
        if skill_script_paths:
            skill_scripts_str = "\n- å¯ç”¨è„šæœ¬ï¼š" + "\n  - ".join(skill_script_paths)
            skill_info += f"\n\n## ğŸ”§ æŠ€èƒ½è„šæœ¬è·¯å¾„{skill_scripts_str}"
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ CRITICAL: æ·»åŠ ä» SKILL.md ä¸­æå–çš„æŒ‡å¼•ï¼ˆæ¸è¿›å¼æŠ«éœ²ï¼‰
        if skill_md_guidance:
            skill_info += f"\n\n{skill_md_guidance}"
            logger.info(
                "Added progressive disclosure guidance from SKILL.md",
                extra={
                    "skill": skill_name,
                    "guidance_chars": len(skill_md_guidance),
                }
            )
        
        # ğŸ”¥ NEW: æ·»åŠ å·¥ä½œç›®å½•å’Œæ–‡ä»¶è·¯å¾„æŒ‡å¼•
        if workspace_path:
            workspace_guidance = f"\n\n## ğŸ“ å·¥ä½œç›®å½•é…ç½®\n"
            workspace_guidance += f"- **ä½ çš„å·¥ä½œç›®å½•æ˜¯ï¼š** `{workspace_path}`\n"
            workspace_guidance += f"- **æ‰€æœ‰æ–‡ä»¶å¿…é¡»ä¿å­˜åˆ°å·¥ä½œç›®å½•ä¸‹ï¼**\n"
            workspace_guidance += f"- âœ… æ­£ç¡®ç¤ºä¾‹ï¼š`{workspace_path}/pdfs/report.pdf`\n"
            workspace_guidance += f"- âŒ é”™è¯¯ç¤ºä¾‹ï¼š`/tmp/report.pdf` æˆ–å…¶ä»–ç›®å½•\n"
            
            # ğŸ”¥ğŸ”¥ğŸ”¥ å…³é”®ï¼šæ˜ç¡®åŒºåˆ†è„šæœ¬è·¯å¾„å’Œè¾“å‡ºæ–‡ä»¶è·¯å¾„
            workspace_guidance += f"\n\n## ğŸ”§ æŠ€èƒ½è„šæœ¬è·¯å¾„ä½¿ç”¨è¯´æ˜\n"
            workspace_guidance += f"- **è„šæœ¬è·¯å¾„**: ä½¿ç”¨ **ç›¸å¯¹è·¯å¾„** æˆ– **ç›´æ¥å†™è„šæœ¬å**ï¼ˆç³»ç»Ÿä¼šè‡ªåŠ¨æŸ¥æ‰¾ï¼‰\n"
            workspace_guidance += f"  - âœ… æ­£ç¡®ï¼š`python create_pdf_from_md.py ...`ï¼ˆæ¨èï¼‰\n"
            workspace_guidance += f"  - âœ… ä¹Ÿå¯ï¼š`python skills/pdf/scripts/create_pdf_from_md.py ...`\n"
            workspace_guidance += f"  - âŒ é”™è¯¯ï¼š`python /workspace/.../create_pdf_from_md.py`ï¼ˆä¸è¦ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰\n"
            workspace_guidance += f"- **è¾“å‡ºæ–‡ä»¶è·¯å¾„**: å¿…é¡»ä½¿ç”¨å®Œæ•´çš„ workspace_path\n"
            workspace_guidance += f"  - âœ… æ­£ç¡®ï¼š`{workspace_path}/pdfs/output.pdf`\n"
            workspace_guidance += f"  - âŒ é”™è¯¯ï¼š`/tmp/output.pdf` æˆ– `./output.pdf`\n"
            
            skill_info += workspace_guidance
        
        prompt = self.SYSTEM_PROMPT.format(
            skill_info=skill_info,
            tools=", ".join(tools_list)
        )
        
        # æ·»åŠ ç”¨æˆ·ç›®æ ‡
        user_prompt = f"ç”¨æˆ·æŒ‡ä»¤ï¼š{goal}\n\nè¯·ç”Ÿæˆç»“æ„åŒ–è®¡åˆ’ï¼ˆJSON æ ¼å¼ï¼‰ï¼š"
        
        try:
            # è°ƒç”¨ LLM ç”Ÿæˆè®¡åˆ’
            response = await self.llm_router.chat(
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": user_prompt}
                ],
                stream=False,
            )
            
            # è§£æ LLM å“åº”ä¸º StructuredPlan
            plan_dict = self._parse_llm_response(response.content)
            structured_plan = self._dict_to_structured_plan(plan_dict, skill_name)
            
            # å¦‚æœ LLM æ²¡æœ‰è¿”å› tool_constraintsï¼Œä½¿ç”¨æˆ‘ä»¬ç”Ÿæˆçš„
            if structured_plan.tool_constraints is None and tool_constraints:
                structured_plan.tool_constraints = tool_constraints
                logger.info(
                    "Applied default tool constraints from task type",
                    extra={"constraints": tool_constraints}
                )
            
            logger.info(
                "Structured plan generation completed",
                extra={
                    "steps_count": len(structured_plan.steps),
                    "milestones_count": len(structured_plan.milestones),
                    "skill_binding": structured_plan.skill_binding,
                    "tool_constraints": structured_plan.tool_constraints,
                }
            )
            
            return structured_plan
            
        except Exception as e:
            logger.warning(
                "Structured plan generation failed, using fallback",
                extra={"error": str(e)}
            )
            # é™çº§ï¼šç”Ÿæˆç®€å•çš„é»˜è®¤è®¡åˆ’
            return self._generate_fallback_plan(goal, skill_name, tool_constraints)
    
    def _parse_llm_response(self, content: str) -> dict:
        """è§£æ LLM çš„ JSON å“åº”"""
        import json
        
        # æ¸…ç† markdown ä»£ç å—
        content = content.strip()
        if content.startswith("```json"):
            content = content[7:]
        if content.endswith("```"):
            content = content[:-3]
        content = content.strip()
        
        try:
            return json.loads(content)
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse LLM JSON: {e}")
            # å°è¯•æå– JSON éƒ¨åˆ†
            import re
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            raise
    
    def _dict_to_structured_plan(self, data: dict, skill_name: str | None) -> StructuredPlan:
        """å°†å­—å…¸è½¬æ¢ä¸º StructuredPlan å¯¹è±¡"""
        # è½¬æ¢ steps
        steps = []
        for step_data in data.get("steps", []):
            validation = None
            if step_data.get("validation"):
                v = step_data["validation"]
                validation = StepValidation(
                    validation_type=v.get("type", "tool_output"),
                    pattern=v.get("pattern"),
                    text=v.get("text"),
                    schema=v.get("schema"),
                )
            
            step = PlanStep(
                id=step_data.get("id", f"step_{len(steps)+1}"),
                name=step_data.get("name", ""),
                description=step_data.get("description"),  # ğŸ”¥ ADD: Parse description
                skill_command=step_data.get("skill_command"),
                tool=step_data.get("tool"),
                expected_output=step_data.get("expected_output"),
                validation=validation,
            )
            steps.append(step)
        
        # è½¬æ¢ milestones
        milestones = []
        for m_data in data.get("milestones", []):
            milestone = Milestone(
                name=m_data.get("name", ""),
                after_step=m_data.get("after_step", ""),
                check_type=m_data.get("check_type", "tool_output"),
                value=m_data.get("value"),
            )
            milestones.append(milestone)
        
        # è½¬æ¢ tool_constraints
        tc_data = data.get("tool_constraints", {})
        tool_constraints = ToolConstraints(
            allowed=tc_data.get("allowed", []),
            forbidden=tc_data.get("forbidden", []),
            source=tc_data.get("source", "plan"),  # âœ… é»˜è®¤ä¸º planï¼Œè¡¨ç¤ºæ¥è‡ª Plan ç”Ÿæˆ
            priority=tc_data.get("priority", 10),  # âœ… Plan çº¦æŸé»˜è®¤é«˜ä¼˜å…ˆçº§
        ) if tc_data else None
        
        return StructuredPlan(
            version=data.get("version", "2.0"),
            goal=data.get("goal", ""),
            skill_binding=data.get("skill_binding") or skill_name,
            tool_constraints=tool_constraints,
            steps=steps,
            milestones=milestones,
            metadata=data.get("metadata", {}),
        )
    
    def _generate_fallback_plan(self, goal: str, skill_name: str | None, tool_constraints: ToolConstraints | None) -> StructuredPlan:
        """ç”Ÿæˆé™çº§è®¡åˆ’ï¼ˆå½“ LLM å¤±è´¥æ—¶ï¼‰"""
        steps = [
            PlanStep(id="step_1", name="åˆ†æä»»åŠ¡éœ€æ±‚", tool="read_file", expected_output="ç†è§£ç”¨æˆ·éœ€æ±‚"),
            PlanStep(id="step_2", name="æ”¶é›†å¿…è¦ä¿¡æ¯", tool="web_search", expected_output="ç›¸å…³ä¿¡æ¯åˆ—è¡¨"),
            PlanStep(id="step_3", name="æ‰§è¡Œæ ¸å¿ƒæ“ä½œ", tool="run_in_terminal", expected_output="æ“ä½œå®Œæˆ"),
            PlanStep(id="step_4", name="éªŒè¯ç»“æœ", tool="read_file", expected_output="éªŒè¯é€šè¿‡"),
        ]
        
        return StructuredPlan(
            version="2.0",
            goal=goal,
            skill_binding=skill_name,
            tool_constraints=tool_constraints,
            steps=steps,
            milestones=[],
        )


# å…¨å±€å®ä¾‹
_structured_planner: StructuredPlanner | None = None


def get_structured_planner(llm_router: LLMRouter | None = None, skill_registry: SkillRegistry | None = None) -> StructuredPlanner:
    """è·å–å…¨å±€ StructuredPlanner å®ä¾‹
    
    Args:
        llm_router: LLM è·¯ç”±å™¨å®ä¾‹ï¼ˆé¦–æ¬¡è°ƒç”¨æ—¶éœ€è¦ï¼‰
        skill_registry: æŠ€èƒ½æ³¨å†Œè¡¨å®ä¾‹ï¼ˆé¦–æ¬¡è°ƒç”¨æ—¶éœ€è¦ï¼‰
    """
    global _structured_planner
    if _structured_planner is None:
        if llm_router is None:
            from ..services.llm.router import get_llm_router
            llm_router = get_llm_router()
        if skill_registry is None:
            from ..services.skill_registry import get_skill_registry
            from pathlib import Path
            skill_registry = get_skill_registry(Path.cwd())
        _structured_planner = StructuredPlanner(llm_router, skill_registry)
    return _structured_planner
