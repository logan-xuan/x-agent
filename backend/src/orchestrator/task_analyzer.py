"""Task complexity analyzer for X-Agent.

Analyzes user messages to determine if a plan should be injected into ReAct.
Uses hybrid approach: rule-based + LLM-assisted judgment for accuracy.
"""

from dataclasses import dataclass, field
from typing import Literal

from ..config.models import SkillsConfig
from ..services.skill_router import get_skill_router  # NEW: Import semantic router
from ..utils.logger import get_logger

logger = get_logger(__name__)


@dataclass
class TaskAnalysis:
    """ä»»åŠ¡åˆ†æç»“æœ
    
    Attributes:
        complexity: ä»»åŠ¡å¤æ‚åº¦ (simple/complex)
        confidence: å¤æ‚åº¦ç½®ä¿¡åº¦ (0.0-1.0)
        indicators: å¤æ‚åº¦æŒ‡æ ‡åˆ—è¡¨
        needs_plan: æ˜¯å¦éœ€è¦æ³¨å…¥è®¡åˆ’
        matched_skills: åŒ¹é…åˆ°çš„æŠ€èƒ½åˆ—è¡¨ï¼ˆåŸºäºå…³é”®è¯ï¼‰
        recommended_skill: æ¨èä½¿ç”¨çš„æŠ€èƒ½ï¼ˆå¦‚æœæœ‰é«˜åŒ¹é…åº¦ï¼‰
        analysis_method: åˆ†ææ–¹æ³• (rule_based/llm_assisted/hybrid)
    """
    complexity: Literal["simple", "complex"]
    confidence: float
    indicators: list[str] = field(default_factory=list)
    needs_plan: bool = False
    matched_skills: list[dict] = field(default_factory=list)
    recommended_skill: dict | None = None
    analysis_method: str = "rule_based"


class TaskAnalyzer:
    """åˆ†æä»»åŠ¡å¤æ‚åº¦ï¼Œå†³å®šæ˜¯å¦éœ€è¦è®¡åˆ’å¼•å¯¼
    
    ä½¿ç”¨çº¯è§„åˆ™åŒ¹é…ï¼ˆæ—  LLM è°ƒç”¨ï¼‰ï¼Œå¿«é€Ÿåˆ¤æ–­ä»»åŠ¡æ˜¯å¦éœ€è¦æ³¨å…¥è®¡åˆ’ã€‚
    
    å¤æ‚åº¦åˆ¤æ–­ä¾æ®ï¼š
    1. å¤šæ­¥éª¤å…³é”®è¯ï¼šå…ˆã€ç„¶åã€æ¥ç€ã€æœ€åã€æ­¥éª¤ã€æµç¨‹ç­‰
    2. æ¡ä»¶åˆ¤æ–­å…³é”®è¯ï¼šå¦‚æœã€å½“ã€åˆ¤æ–­ã€æ£€æŸ¥ã€ç¡®è®¤ç­‰
    3. è¿­ä»£å…³é”®è¯ï¼šæ‰€æœ‰ã€æ¯ä¸ªã€æ‰¹é‡ã€éå†ã€å¾ªç¯ç­‰
    4. ä¸ç¡®å®šæ€§å…³é”®è¯ï¼šå¯èƒ½ã€æˆ–è€…ã€ä¸ç¡®å®šã€è¯•è¯•ç­‰
    5. èŒƒå›´å…³é”®è¯ï¼šé‡æ„ã€è¿ç§»ã€æ­å»ºã€å®ç°ã€è®¾è®¡ç­‰
    6. æ¶ˆæ¯é•¿åº¦ï¼šè¶…è¿‡ 200 å­—ç¬¦
    7. å¥å­æ•°é‡ï¼šè¶…è¿‡ 3 ä¸ªå¥å­
    8. æŠ€èƒ½å…³é”®è¯ï¼šåŒ¹é…æ³¨å†Œçš„æŠ€èƒ½å…³é”®è¯
    """
    
    # å¤æ‚åº¦æŒ‡æ ‡ï¼ˆè§„åˆ™å¿«é€ŸåŒ¹é…ï¼‰
    COMPLEXITY_INDICATORS = {
        "multi_step": ["å…ˆ", "ç„¶å", "æ¥ç€", "æœ€å", "æ­¥éª¤", "æµç¨‹", "ç¬¬ä¸€æ­¥", "ç¬¬äºŒæ­¥", "ç¬¬ä¸‰æ­¥"],
        "conditional": ["å¦‚æœ", "å½“", "åˆ¤æ–­", "æ£€æŸ¥", "ç¡®è®¤", "éªŒè¯", "å¦åˆ™"],
        "iteration": ["æ‰€æœ‰", "æ¯ä¸ª", "æ‰¹é‡", "éå†", "å¾ªç¯", "å…¨éƒ¨", "é€ä¸ª"],
        "uncertainty": ["å¯èƒ½", "æˆ–è€…", "ä¸ç¡®å®š", "è¯•è¯•", "å°è¯•", "ä¹Ÿè®¸"],
        "scope": ["é‡æ„", "è¿ç§»", "æ­å»º", "å®ç°", "è®¾è®¡", "æ„å»º", "å¼€å‘"],
        # NEW: Action verbs indicating complex tasks
        "action_verbs": ["ç ”ç©¶", "åˆ†æ", "è°ƒæŸ¥", "æ¢ç´¢", "è¯„ä¼°", "æ€»ç»“", "å½’çº³", "æ•´ç†", "æ”¶é›†"],
        # NEW: Target objects indicating output generation
        "target_objects": ["æ–‡ç« ", "æŠ¥å‘Š", "è®ºæ–‡", "æ–‡æ¡£", "PDF", "PPT", "æ¼”ç¤º", "è¡¨æ ¼", "æ•°æ®"],
        # NEW: Research and creation keywords
        "research_creation": ["æ·±åº¦", "å…¨é¢", "ç³»ç»Ÿ", "è¯¦ç»†", "å®Œæ•´", "è¶‹åŠ¿", "å‘å±•", "å±•æœ›"],
    }
    
    # å¤æ‚åº¦é˜ˆå€¼
    COMPLEXITY_THRESHOLD = 0.6
    
    def __init__(self, skills_config: SkillsConfig | None = None, skill_router=None, llm_skill_matcher=None) -> None:
        """åˆå§‹åŒ–ä»»åŠ¡åˆ†æå™¨
        
        Args:
            skills_config: æŠ€èƒ½å…ƒæ•°æ®é…ç½®ï¼ˆå¯é€‰ï¼‰
            skill_router: è¯­ä¹‰è·¯ç”±å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼ŒåŸºäºå‘é‡ç›¸ä¼¼åº¦ï¼‰
            llm_skill_matcher: LLM æŠ€èƒ½åŒ¹é…å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼Œæ¨èä½¿ç”¨ï¼‰
        """
        self.skills_config = skills_config
        self.skill_router = skill_router  # åŸºäºå‘é‡çš„è¯­ä¹‰è·¯ç”±ï¼ˆä¿ç•™å‘åå…¼å®¹ï¼‰
        
        # P3-0 NEW: Initialize LLM-based skill matcher (preferred method)
        if llm_skill_matcher:
            # Use provided LLM matcher instance
            self.llm_skill_matcher = llm_skill_matcher
            logger.debug("LLM skill matcher initialized with provided instance")
        else:
            # Try to initialize default matcher
            try:
                from .llm_skill_matcher import get_llm_skill_matcher
                self.llm_skill_matcher = get_llm_skill_matcher()
                logger.debug("LLM skill matcher initialized with default instance")
            except Exception as e:
                logger.warning(f"Failed to initialize LLM skill matcher: {e}")
                self.llm_skill_matcher = None
    
    @staticmethod
    def parse_skill_command(user_message: str) -> tuple[str, str]:
        """è§£æ /command æ ¼å¼çš„å‘½ä»¤ï¼Œæå–æŠ€èƒ½åç§°å’Œå‚æ•°
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            
        Returns:
            (skill_name, arguments) å…ƒç»„
            - å¦‚æœä¸æ˜¯ /command æ ¼å¼ï¼Œè¿”å› ("", user_message)
            - å¦‚æœæ˜¯ /command æ ¼å¼ï¼Œè¿”å› (æŠ€èƒ½åï¼Œå‚æ•°)
            
        Examples:
            >>> parse_skill_command("/pptx create test.pptx")
            ('pptx', 'create test.pptx')
            
            >>> parse_skill_command("/pdf")
            ('pdf', '')
            
            >>> parse_skill_command("Hello")
            ('', 'Hello')
        """
        if not user_message.startswith('/'):
            return "", user_message
        
        # ç§»é™¤å¼€å¤´çš„ / å¹¶åˆ†å‰²
        parts = user_message[1:].split(' ', 1)
        skill_name = parts[0].strip()
        arguments = parts[1].strip() if len(parts) > 1 else ""
        
        return skill_name, arguments
    
    async def analyze_with_llm(self, user_message: str) -> TaskAnalysis | None:
        """ä½¿ç”¨ LLM è¾…åŠ©åˆ¤æ–­ä»»åŠ¡å¤æ‚åº¦ï¼ˆå¯é€‰ï¼‰
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            
        Returns:
            TaskAnalysis: LLM åˆ†æç»“æœï¼Œå¦‚æœ LLM åˆ¤æ–­å¤±è´¥åˆ™è¿”å› None
        """
        try:
            # ğŸ”¥ FIX 1: Handle simple greetings without LLM call
            simple_greetings = ["ä½ å¥½", "æ‚¨å¥½", "hello", "hi", "æ—©ä¸Šå¥½", "ä¸­åˆå¥½", "æ™šä¸Šå¥½", "å†è§", "bye"]
            if any(greeting in user_message.lower() for greeting in simple_greetings):
                logger.info("Simple greeting detected, no need for complex analysis")
                return TaskAnalysis(
                    complexity="simple",
                    confidence=0.95,
                    indicators=["simple_greeting"],
                    needs_plan=False,
                    matched_skills=[],
                    recommended_skill=None,
                    analysis_method="rule_based",
                )
            
            # ğŸ”¥ FIX 2: Use absolute import instead of relative import
            from src.services.llm.router import get_llm_router
            llm_router = get_llm_router()
            
            # æ„å»º prompt
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä»»åŠ¡è§„åˆ’ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ¤æ–­ç”¨æˆ·è¯·æ±‚æ˜¯å¦éœ€è¦ç»“æ„åŒ–è®¡åˆ’ï¼ˆPlan Modeï¼‰ã€‚

åˆ¤æ–­æ ‡å‡†ï¼š
- **éœ€è¦ Plan**ï¼šå¤šæ­¥éª¤ä»»åŠ¡ã€ç ”ç©¶åˆ†æã€å†…å®¹åˆ›ä½œã€æ•°æ®å¤„ç†ã€ä½¿ç”¨ç‰¹å®šæŠ€èƒ½ï¼ˆå¦‚ PDF/PPT ç”Ÿæˆï¼‰
- **ä¸éœ€è¦ Plan**ï¼šç®€å•é—®ç­”ã€å·¥å…·ç¡®è®¤ã€çŠ¶æ€æŸ¥è¯¢ã€å•æ­¥æ“ä½œ

è¯·åªè¿”å› JSON æ ¼å¼ï¼š
```json
{
  "needs_plan": true/false,
  "complexity": "simple"/"complex",
  "confidence": 0.0-1.0,
  "reason": "ç®€çŸ­è¯´æ˜ç†ç”±"
}
```"""
            
            user_prompt = f"ç”¨æˆ·è¯·æ±‚ï¼š{user_message}\n\nè¯·åˆ¤æ–­æ˜¯å¦éœ€è¦ç»“æ„åŒ–è®¡åˆ’ï¼š"
            
            # è°ƒç”¨ LLM
            response = await llm_router.chat(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                stream=False,
            )
            
            # è§£æå“åº”
            import json
            content = response.content.strip()
            
            # å°è¯•æå– JSON
            if '```json' in content:
                json_str = content.split('```json')[1].split('```')[0].strip()
            elif '{' in content and '}' in content:
                start = content.find('{')
                end = content.rfind('}') + 1
                json_str = content[start:end]
            else:
                logger.warning(f"LLM response not in JSON format: {content[:100]}")
                return None
            
            result = json.loads(json_str)
            
            needs_plan = result.get('needs_plan', False)
            complexity = result.get('complexity', 'simple' if not needs_plan else 'complex')
            confidence = float(result.get('confidence', 0.5))
            reason = result.get('reason', '')
            
            logger.info(
                "LLM-assisted task analysis completed",
                extra={
                    "needs_plan": needs_plan,
                    "complexity": complexity,
                    "confidence": confidence,
                    "reason": reason[:100] if reason else '',
                }
            )
            
            return TaskAnalysis(
                complexity=complexity,
                confidence=confidence,
                indicators=[f"llm_reason: {reason}"],
                needs_plan=needs_plan,
                matched_skills=[],
                recommended_skill=None,
                analysis_method="llm_assisted",
            )
            
        except Exception as e:
            logger.warning(f"LLM-assisted analysis failed: {e}")
            return None
    
    @staticmethod
    def extract_skill_name(user_message: str, available_skills: list[str] | None = None) -> tuple[str, str]:
        """ä»ç”¨æˆ·æ¶ˆæ¯ä¸­æå–æŠ€èƒ½åç§°ï¼ˆæ”¯æŒæœ‰/å’Œæ— /çš„æƒ…å†µï¼‰
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            available_skills: å¯ç”¨æŠ€èƒ½åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰ï¼Œç”¨äºç²¾ç¡®åŒ¹é…
            
        Returns:
            (skill_name, remaining_message) å…ƒç»„
            - å¦‚æœåŒ¹é…åˆ°æŠ€èƒ½ï¼Œè¿”å› (æŠ€èƒ½åï¼Œå‰©ä½™æ¶ˆæ¯)
            - å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œè¿”å› ("", user_message)
            
        Examples:
            >>> extract_skill_name("/pdf convert file.pdf")
            ('pdf', 'convert file.pdf')
            
            >>> extract_skill_name("pptx create presentation")
            ('pptx', 'create presentation')
        """
        # å…ˆå°è¯• /command æ ¼å¼
        skill_name, remaining = TaskAnalyzer.parse_skill_command(user_message)
        if skill_name:
            return skill_name, remaining
        
        # NEW: å°è¯•æ¨¡ç³ŠåŒ¹é… - æ£€æŸ¥æ¶ˆæ¯ä¸­æ˜¯å¦åŒ…å«æŠ€èƒ½åï¼ˆä¸åªåœ¨å¼€å¤´ï¼‰
        if available_skills:
            message_lower = user_message.lower()
            
            # ç­–ç•¥ 1: æ£€æŸ¥æ˜¯å¦ä»¥æŸä¸ªæŠ€èƒ½åå¼€å¤´ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            words = user_message.split()
            if words:
                first_word = words[0].lower()
                for skill in available_skills:
                    if skill.lower() == first_word:
                        remaining_msg = ' '.join(words[1:]) if len(words) > 1 else ""
                        return skill, remaining_msg
            
            # NEW ç­–ç•¥ 2: æ£€æŸ¥æ¶ˆæ¯ä¸­æ˜¯å¦åŒ…å«æŠ€èƒ½åï¼ˆæ›´çµæ´»ï¼‰
            # ä¾‹å¦‚ï¼š"ç”Ÿæˆ pdf"ä¸­åŒ…å«"pdf"
            for skill in available_skills:
                skill_lower = skill.lower()
                if skill_lower in message_lower:
                    # æ‰¾åˆ°æŠ€èƒ½ååœ¨æ¶ˆæ¯ä¸­çš„ä½ç½®
                    skill_pos = message_lower.find(skill_lower)
                    
                    # æå–æŠ€èƒ½åå‰åçš„å†…å®¹
                    before = user_message[:skill_pos].strip()
                    after = user_message[skill_pos + len(skill):].strip()
                    
                    # å¦‚æœæŠ€èƒ½åå‰é¢æ˜¯åŠ¨è¯ï¼ˆå¦‚"ç”Ÿæˆ"ã€"åˆ›å»º"ï¼‰ï¼Œä¹Ÿè®¤ä¸ºæ˜¯æŠ€èƒ½è°ƒç”¨
                    action_verbs = ["ç”Ÿæˆ", "åˆ›å»º", "åˆ¶ä½œ", "åš", "å†™", "ç”»", "è½¬æ¢", "å¤„ç†"]
                    if any(verb in before for verb in action_verbs) or not before:
                        # è¿”å›æŠ€èƒ½åå’Œå‰©ä½™å†…å®¹ä½œä¸ºå‚æ•°
                        remaining_msg = f"{before} {after}".strip() if before or after else ""
                        return skill, remaining_msg
        
        return "", user_message
    
    async def analyze(self, user_message: str) -> TaskAnalysis:
        """åˆ†æä»»åŠ¡å¤æ‚åº¦
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯å†…å®¹
            
        Returns:
            TaskAnalysis: åˆ†æç»“æœ
        """
        if not user_message:
            return TaskAnalysis(
                complexity="simple",
                confidence=0.0,
                indicators=[],
                needs_plan=False,
                matched_skills=[],
                recommended_skill=None,
            )
        
        # ğŸ”¥ NEW: æ£€æµ‹å·¥å…·ç¡®è®¤ä¸Šä¸‹æ–‡ï¼Œé¿å…è¯¯åˆ¤
        # å¦‚æœæ¶ˆæ¯åŒ…å«"[ç”¨æˆ·å·²ç¡®è®¤æ‰§è¡Œé«˜å±å‘½ä»¤]"ï¼Œè¯´æ˜æ˜¯å·¥å…·ç¡®è®¤åçš„ç»§ç»­æ‰§è¡Œ
        # è¿™ç§æƒ…å†µä¸‹ä¸åº”è¯¥é‡æ–°è¿›è¡Œä»»åŠ¡åˆ†æï¼Œè€Œæ˜¯ä¿æŒåŸæœ‰çš„è®¡åˆ’çŠ¶æ€
        if "[ç”¨æˆ·å·²ç¡®è®¤æ‰§è¡Œé«˜å±å‘½ä»¤]" in user_message:
            logger.info(
                "Tool confirmation context detected, skipping complexity analysis",
                extra={"message_preview": user_message[:100]}
            )
            
            # ğŸ”¥ NEW: å³ä½¿æ˜¯åœ¨å·¥å…·ç¡®è®¤ä¸Šä¸‹æ–‡ä¸­ï¼Œä¹Ÿè¦æ£€æŸ¥æ˜¯å¦æœ‰ PDF ç­‰å¤æ‚éœ€æ±‚
            pdf_keywords = ["pdf", "PDF", "ç”Ÿæˆ pdf", "åˆ›å»º pdf", "pdf æŠ¥å‘Š"]
            has_pdf_need = any(kw in user_message for kw in pdf_keywords)
            
            if has_pdf_need:
                logger.info(
                    "PDF requirement detected in tool confirmation context",
                    extra={"matched_pdf_keywords": [kw for kw in pdf_keywords if kw in user_message]}
                )
                return TaskAnalysis(
                    complexity="complex",
                    confidence=0.85,
                    indicators=["tool_confirmation_context_with_pdf_need"],
                    needs_plan=True,  # ğŸ”¥ éœ€è¦ Plan Mode
                    matched_skills=[],
                    recommended_skill=None,
                )
            
            # å¦åˆ™ç¡®å®æ˜¯ç®€å•ä»»åŠ¡ï¼ˆåªæ˜¯ç»§ç»­æ‰§è¡Œå·²ç¡®è®¤çš„å‘½ä»¤ï¼‰
            return TaskAnalysis(
                complexity="simple",
                confidence=0.9,  # é«˜ç½®ä¿¡åº¦è¿™æ˜¯ç¡®è®¤ä¸Šä¸‹æ–‡
                indicators=["tool_confirmation_context"],
                needs_plan=False,  # ä¸åº”è¯¥é‡æ–°ç”Ÿæˆè®¡åˆ’ï¼Œåº”è¯¥ç»§ç»­æ‰§è¡ŒåŸæœ‰è®¡åˆ’
                matched_skills=[],
                recommended_skill=None,
            )
        
        # ===== P1: /command æ ¼å¼å¼ºåˆ¶ Plan Mode =====
        skill_name, arguments = self.parse_skill_command(user_message)
        if skill_name:
            # ç”¨æˆ·æ˜ç¡®è°ƒç”¨äº†æŠ€èƒ½å‘½ä»¤ï¼Œè¿™é€šå¸¸æ˜¯å¤æ‚ä»»åŠ¡
            # Fix: matched_skills must be list of dicts, not list of strings
            return TaskAnalysis(
                complexity="complex",
                confidence=1.0,
                indicators=[f"skill_name_detected: {skill_name}"],
                needs_plan=True,  # Always need plan when skill is explicitly invoked
                matched_skills=[{"name": skill_name}],
                recommended_skill={"name": skill_name, "arguments": arguments},
                analysis_method="rule_based",
            )
        
        # ===== P2: LLM è¾…åŠ©åˆ¤æ–­ï¼ˆæ··åˆæ¨¡å¼ï¼‰=====
        # å…ˆå°è¯•ä½¿ç”¨ LLM åˆ¤æ–­ï¼Œå¦‚æœ LLM åˆ¤æ–­ç½®ä¿¡åº¦é«˜åˆ™ç›´æ¥é‡‡ç”¨
        llm_analysis = await self.analyze_with_llm(user_message)
        if llm_analysis and llm_analysis.confidence >= 0.8:
            # LLM åˆ¤æ–­ç½®ä¿¡åº¦é«˜ï¼Œç›´æ¥é‡‡ç”¨
            logger.info(
                "Using LLM-assisted analysis (high confidence)",
                extra={
                    "confidence": llm_analysis.confidence,
                    "needs_plan": llm_analysis.needs_plan,
                }
            )
            return llm_analysis
        
        # ===== P3: è§„åˆ™åŒ¹é…ï¼ˆfallbackï¼‰=====
        # å¦‚æœ LLM åˆ¤æ–­å¤±è´¥æˆ–ç½®ä¿¡åº¦ä½ï¼Œä½¿ç”¨è§„åˆ™åŒ¹é…
        logger.debug(
            "Falling back to rule-based analysis",
            extra={
                "llm_confidence": llm_analysis.confidence if llm_analysis else None,
            }
        )
        
        # ===== æ–°å¢ï¼šæ”¯æŒæ— æ–œæ çš„æŠ€èƒ½åç§°åŒ¹é… =====
        # å³ä½¿ç”¨æˆ·æ²¡æœ‰è¾“å…¥ /ï¼Œåªè¦æ¶ˆæ¯ä»¥æŠ€èƒ½åå¼€å¤´ï¼Œä¹Ÿè¯†åˆ«ä¸ºæŠ€èƒ½è°ƒç”¨
        if self.skills_config and self.skills_config.registered:
            available_skills = [skill.name for skill in self.skills_config.registered]
            extracted_skill, remaining_msg = self.extract_skill_name(user_message, available_skills)
            
            if extracted_skill:
                logger.info(
                    "Skill name detected without slash prefix",
                    extra={
                        "skill_name": extracted_skill,
                        "original_message": user_message,
                        "remaining_message": remaining_msg,
                    }
                )
                
                # Check if this is a high-confidence skill match
                # If skill appears with action verbs or at the beginning, confidence is higher
                confidence = 0.8
                skill_lower = extracted_skill.lower()
                message_lower = user_message.lower()
                
                # Higher confidence scenarios
                if (message_lower.startswith(skill_lower) or
                    any(verb in user_message[:user_message.lower().find(skill_lower)] 
                        for verb in ["ç”Ÿæˆ", "åˆ›å»º", "åˆ¶ä½œ", "å†™", "ç”»"])):
                    confidence = 0.95
                
                return TaskAnalysis(
                    complexity="complex",
                    confidence=confidence,
                    indicators=[f"skill_name_detected: {extracted_skill}"],
                    needs_plan=True,  # Always need plan when skill is explicitly invoked
                    matched_skills=[{"name": extracted_skill}],
                    recommended_skill={"name": extracted_skill, "arguments": remaining_msg},
                )
        
        score = 0.0
        indicators = []
        
        # å…³é”®è¯åŒ¹é…
        for category, keywords in self.COMPLEXITY_INDICATORS.items():
            matches = [kw for kw in keywords if kw in user_message]
            if matches:
                score += len(matches) * 0.2
                indicators.append(f"{category}: {matches}")
        
        # é•¿åº¦è¾…åŠ©åˆ¤æ–­
        if len(user_message) > 200:
            score += 0.3
        
        # å¥å­æ•°é‡è¾…åŠ©åˆ¤æ–­
        sentence_count = user_message.count("ã€‚") + user_message.count("ï¼›") + user_message.count("ï¼Ÿ")
        if sentence_count > 3:
            score += 0.2
        
        # æŠ€èƒ½å…³é”®è¯åŒ¹é…ï¼ˆåŸæœ‰é€»è¾‘ï¼‰+ P2-2 NEW: è¯­ä¹‰è·¯ç”±å¢å¼º + P3-0 NEW: LLM æ™ºèƒ½åŒ¹é…
        matched_skills = []
        recommended_skill = None
        
        if self.skills_config and self.skills_config.registered:
            # Step 1: åŸæœ‰çš„å…³é”®è¯åŒ¹é…
            keyword_matched = self.skills_config.match_skills_by_keywords(user_message)
            
        # P3-0 NEW: Step 2 - ä¼˜å…ˆä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½åŒ¹é…ï¼ˆæœ€å‡†ç¡®ï¼‰
            llm_matches = []
            if self.llm_skill_matcher:
                try:
                    # âœ… FIX: Use await directly in async context
                    llm_matches = await self.llm_skill_matcher.match_skills(user_message, top_k=3)
                    logger.info(
                        "LLM-based skill matching completed",
                        extra={
                            "task": user_message[:50],
                            "llm_matches": llm_matches,
                        }
                    )
                except Exception as e:
                    logger.warning(f"LLM skill matching failed: {e}")
                    llm_matches = []
            
            # P2-2 NEW: Step 3 - ä½¿ç”¨è¯­ä¹‰è·¯ç”±åŒ¹é… Skillsï¼ˆé™çº§æ–¹æ¡ˆï¼‰
            semantic_matches = []
            if self.skill_router and not llm_matches:  # LLM å¤±è´¥æ—¶æ‰ä½¿ç”¨
                try:
                    semantic_matches = self.skill_router.route(user_message, top_k=3)
                    logger.info(
                        "Semantic skill matching completed (fallback)",
                        extra={
                            "task": user_message[:50],
                            "semantic_matches": semantic_matches,
                        }
                    )
                except Exception as e:
                    logger.warning(f"Semantic routing failed: {e}")
            
            # Step 4: åˆå¹¶åŒ¹é…ç»“æœï¼ˆä¼˜å…ˆçº§ï¼šLLM > è¯­ä¹‰ > å…³é”®è¯ï¼‰
            seen_skills = set()
            all_matched = []
            
            # ä¼˜å…ˆæ·»åŠ  LLM åŒ¹é…çš„ç»“æœï¼ˆæœ€å‡†ç¡®ï¼‰
            for skill_name, score in llm_matches:
                if score >= 0.6 and skill_name not in seen_skills:  # ç½®ä¿¡åº¦é˜ˆå€¼ 0.6
                    skill = self.skills_config.get_skill_by_name(skill_name)
                    if skill:
                        skill_info = {
                            "name": skill.name,
                            "description": skill.description,
                            "priority": skill.priority,
                            "auto_trigger": skill.auto_trigger,
                            "match_score": score,  # LLM ç½®ä¿¡åº¦
                            "match_type": "llm",  # æ ‡è®°ä¸º LLM åŒ¹é…
                        }
                        all_matched.append(skill_info)
                        seen_skills.add(skill_name)
                        
                        # é«˜ç½®ä¿¡åº¦åŒ¹é…ï¼ˆ>0.8ï¼‰è‡ªåŠ¨æ¨è
                        if score > 0.8 and recommended_skill is None:
                            recommended_skill = skill_info
                            score += 0.3  # æé«˜å¤æ‚åº¦è¯„åˆ†
                            indicators.append(f"llm_skill_matched: {skill.name} (confidence: {score:.2f})")
            
            # å…¶æ¬¡æ·»åŠ è¯­ä¹‰åŒ¹é…çš„ç»“æœ
            for skill_name, score in semantic_matches:
                if score >= 0.6 and skill_name not in seen_skills:
                    skill = self.skills_config.get_skill_by_name(skill_name)
                    if skill:
                        skill_info = {
                            "name": skill.name,
                            "description": skill.description,
                            "priority": skill.priority,
                            "auto_trigger": skill.auto_trigger,
                            "match_score": score,
                            "match_type": "semantic",  # æ ‡è®°ä¸ºè¯­ä¹‰åŒ¹é…
                        }
                        all_matched.append(skill_info)
                        seen_skills.add(skill_name)
                        
                        # é«˜ç½®ä¿¡åº¦åŒ¹é…ï¼ˆ>0.8ï¼‰è‡ªåŠ¨æ¨è
                        if score > 0.8 and recommended_skill is None:
                            recommended_skill = skill_info
                            score += 0.3
                            indicators.append(f"semantic_skill_matched: {skill.name} (score: {score:.2f})")
            
            # æœ€åæ·»åŠ å…³é”®è¯åŒ¹é…çš„ç»“æœ
            for skill in keyword_matched:
                if skill.name not in seen_skills:
                    skill_info = {
                        "name": skill.name,
                        "description": skill.description,
                        "priority": skill.priority,
                        "auto_trigger": skill.auto_trigger,
                        "match_type": "keyword",  # æ ‡è®°ä¸ºå…³é”®è¯åŒ¹é…
                    }
                    all_matched.append(skill_info)
                    seen_skills.add(skill.name)
                    
                    # å¦‚æœæ˜¯è‡ªåŠ¨è§¦å‘æŠ€èƒ½ï¼Œè®¾ä¸ºæ¨è
                    if skill.auto_trigger and recommended_skill is None:
                        recommended_skill = skill_info
                        score += 0.3
                        indicators.append(f"keyword_skill_matched: {skill.name}")
            
            matched_skills = all_matched
        
        # é™åˆ¶ç½®ä¿¡åº¦åœ¨ 0-1 èŒƒå›´
        confidence = min(score, 1.0)
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦è®¡åˆ’
        needs_plan = confidence > self.COMPLEXITY_THRESHOLD
        
        # å¦‚æœåŒ¹é…åˆ°é«˜ä¼˜å…ˆçº§æŠ€èƒ½ï¼Œé™ä½è®¡åˆ’é˜ˆå€¼ï¼ˆæŠ€èƒ½ç›¸å…³ä»»åŠ¡é€šå¸¸æ›´å¤æ‚ï¼‰
        if recommended_skill and recommended_skill.get("priority", 999) <= 3:
            needs_plan = needs_plan or confidence > 0.4
        
        return TaskAnalysis(
            complexity="complex" if needs_plan else "simple",
            confidence=confidence,
            indicators=indicators,
            needs_plan=needs_plan,
            matched_skills=matched_skills,
            recommended_skill=recommended_skill,
        )


# å…¨å±€å®ä¾‹
_task_analyzer: TaskAnalyzer | None = None


def get_task_analyzer() -> TaskAnalyzer:
    """è·å–å…¨å±€ TaskAnalyzer å®ä¾‹"""
    global _task_analyzer
    if _task_analyzer is None:
        _task_analyzer = TaskAnalyzer()
    return _task_analyzer
