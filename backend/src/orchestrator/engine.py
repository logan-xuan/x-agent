"""Orchestrator engine for X-Agent.

The Orchestrator is the central coordinator that:
- Loads and applies AGENTS.md policies
- Coordinates context loading
- Manages the ReAct loop
- Executes tools
- Handles memory writing
- Loads session history with context compression

This is the main entry point for processing user requests.
"""

import re
import time
from collections.abc import AsyncGenerator
from pathlib import Path
from typing import Any, TYPE_CHECKING

from .policy_engine import PolicyEngine
from .react_loop import (
    ReActLoop,
    REACT_EVENT_THINKING,
    REACT_EVENT_TOOL_CALL,
    REACT_EVENT_TOOL_RESULT,
    REACT_EVENT_CHUNK,
    REACT_EVENT_FINAL,
    REACT_EVENT_ERROR,
    REACT_EVENT_REFLECTION,  # ‚úÖ FIX: Add missing reflection event
    REACT_EVENT_STRATEGY_ADJUSTMENT,  # ‚úÖ FIX: Add strategy adjustment event too
)
from .guards import SessionGuard, ResponseGuard
from .task_analyzer import TaskAnalyzer, get_task_analyzer
from .structured_planner import StructuredPlanner, get_structured_planner
from .plan_context import PlanContext, PlanState, get_plan_context
from .plan_persistence import PlanPersistence  # üî• NEW: Import persistence
from .plan_monitor import PlanModeMonitor, PlanModeStatus  # ‚úÖ OPTIMIZE: Plan Mode monitor
from .message_builder import MessageBuilder  # NEW: Message builder component
# Use relative imports within the orchestrator package
from .models.plan import StructuredPlan, ToolConstraints
from .validators.tool_validator import ToolConstraintValidator
from .validators.milestone_validator import MilestoneValidator
from ..config.manager import ConfigManager
from ..memory.context_builder import ContextBuilder, get_context_builder
from ..memory.hybrid_search import HybridSearch, get_hybrid_search
from ..memory.md_sync import get_md_sync
from ..memory.models import SessionType
from ..memory.vector_store import get_vector_store
from ..memory.embedder import get_embedder
from ..services.compression import ContextCompressionManager
from ..services.llm.router import LLMRouter
from ..services.smart_memory import get_smart_memory_service
from ..services.skill_registry import SkillRegistry, get_skill_registry
from ..tools.manager import ToolManager, get_tool_manager
from ..tools.builtin import get_builtin_tools
from ..utils.logger import get_logger

if TYPE_CHECKING:
    from ..core.session import SessionManager

logger = get_logger(__name__)


# Orchestrator event types
ORCH_EVENT_POLICY = "policy_check"
ORCH_EVENT_CONTEXT = "context_loaded"
ORCH_EVENT_THINKING = "thinking"
ORCH_EVENT_TOOL_CALL = "tool_call"
ORCH_EVENT_TOOL_RESULT = "tool_result"
ORCH_EVENT_CHUNK = "chunk"
ORCH_EVENT_FINAL = "final_answer"
ORCH_EVENT_ERROR = "error"

# Plan-related event types
ORCH_EVENT_TASK_ANALYSIS = "task_analysis"
ORCH_EVENT_PLAN_GENERATED = "plan_generated"
ORCH_EVENT_PLAN_ADJUSTMENT = "plan_adjustment"


class Orchestrator:
    """Central orchestrator for X-Agent request processing."""
    
    def __init__(
        self,
        workspace_path: str,
        llm_router: LLMRouter | None = None,
        session_manager: "SessionManager | None" = None,
    ) -> None:
        """Initialize the orchestrator.
        
        Args:
            workspace_path: Path to workspace directory
            llm_router: LLM router instance
            session_manager: Session manager for loading conversation history
        """
        # ‚úÖ FIX: Use fully qualified import to avoid UnboundLocalError in Python 3.13
        import pathlib
        self.workspace_path = pathlib.Path(workspace_path).resolve()
        
        # Initialize components
        self.policy_engine = PolicyEngine(str(self.workspace_path))
        self.session_guard = SessionGuard()
        self.response_guard = ResponseGuard()
        
        # Session manager for conversation history
        self._session_manager = session_manager
        
        # Context builder
        self._context_builder: ContextBuilder | None = None
        
        # Hybrid search for memory retrieval
        self._hybrid_search: HybridSearch | None = None
        
        # LLM router
        if llm_router is None:
            from ..config.manager import ConfigManager
            
            config = ConfigManager().config
            self._llm_router = LLMRouter(config.models)
        else:
            self._llm_router = llm_router
        
        # Context compression manager
        self._compression_manager: ContextCompressionManager | None = None
        
        # Tool manager with built-in tools
        self._tool_manager = get_tool_manager()
        self._register_builtin_tools()
        
        # ReAct loop
        self._react_loop = ReActLoop(
            llm_router=self._llm_router,
            tool_manager=self._tool_manager,
        )
        
        # üî• FIX: Plan state cache for tool confirmation inheritance
        # Maps session_id -> PlanState to persist across tool confirmations
        self._plan_state_cache: dict[str, PlanState] = {}
        
        # ‚úÖ OPTIMIZE: Plan Mode monitor for emergency braking
        self._plan_monitor: PlanModeMonitor | None = None
        
        # üî• NEW: Plan file persistence
        self._plan_persistence = PlanPersistence(str(self.workspace_path))
        logger.info(
            "Plan persistence initialized",
            extra={"workspace": str(self.workspace_path)}
        )
        
        # Skill registry for discovering and managing skills
        self._skill_registry = SkillRegistry(self.workspace_path)
        
        # Phase 2: Store current skill context for tool restrictions
        self._current_skill_context: Any = None
        
        # Task planning components
        try:
            config_manager = ConfigManager()
            # Initialize task analyzer with skills config, skill router and LLM skill matcher
            from src.services.skill_router import get_skill_router
            from .llm_skill_matcher import get_llm_skill_matcher
            from pathlib import Path
            
            skill_registry = get_skill_registry(Path.cwd())
            skill_router = get_skill_router(skill_registry)
            llm_skill_matcher = get_llm_skill_matcher(skill_registry)
            
            self._task_analyzer = TaskAnalyzer(
                skills_config=config_manager.config.skills,
                skill_router=skill_router,
                llm_skill_matcher=llm_skill_matcher
            )
            logger.info("Task analyzer initialized with LLM skill matcher")
        except Exception as e:
            logger.warning(f"Failed to initialize task analyzer with skill matcher: {e}")
            # Fallback to default without skills config
            self._task_analyzer = TaskAnalyzer()
        
        # Structured Planner for v2.0 (Áªü‰∏Ä‰ΩøÁî® StructuredPlanner)
        self._structured_planner: StructuredPlanner | None = None
        
        # Plan context manager (uses config from x-agent.yaml)
        from ..config.models import PlanConfig
        
        try:
            config_manager = ConfigManager()
            plan_config = config_manager.config.plan
        except Exception:
            # Fallback to default config if loading fails
            plan_config = PlanConfig()
        
        self._plan_context = PlanContext(config=plan_config)
        
        # Tool constraint validator (will be initialized per request when needed)
        self._tool_validator: ToolConstraintValidator | None = None
        
        # Milestone validator (will be initialized per request when needed)
        self._milestone_validator: MilestoneValidator | None = None
        
        # Skill registry (for discovering and managing skills)
        from ..services.skill_registry import get_skill_registry
        self._skill_registry = get_skill_registry(self.workspace_path)
        
        # Message builder (NEW: Extracted component for system prompt building)
        self._message_builder = MessageBuilder(
            workspace_path=self.workspace_path,
            tool_manager=self._tool_manager,
            skill_registry=self._skill_registry,
            policy_engine=self.policy_engine,
            llm_router=self._llm_router,
        )
        
        logger.info(
            "Orchestrator initialized",
            extra={
                "workspace_path": str(self.workspace_path),
                "tools_count": len(self._tool_manager.get_tool_names()),
                "skills_count": len(self._skill_registry.list_all_skills()),
                "has_session_manager": session_manager is not None,
            }
        )
    
    def _get_context_builder(self) -> ContextBuilder:
        """Get or create context builder."""
        if self._context_builder is None:
            self._context_builder = get_context_builder(str(self.workspace_path))
        return self._context_builder
    
    def _get_session_manager(self) -> "SessionManager":
        """Get or create session manager."""
        if self._session_manager is None:
            from ..core.session import SessionManager
            self._session_manager = SessionManager()
        return self._session_manager
    
    def _get_compression_manager(self) -> ContextCompressionManager:
        """Get or create compression manager."""
        if self._compression_manager is None:
            config = ConfigManager().config
            self._compression_manager = ContextCompressionManager(
                config=config.compression,
                workspace_path=str(self.workspace_path),
                llm_service=self._llm_router,
            )
        return self._compression_manager
    
    def _get_hybrid_search(self) -> HybridSearch:
        """Get or create hybrid search instance."""
        if self._hybrid_search is None:
            try:
                vector_store = get_vector_store()
                embedder = get_embedder()
                self._hybrid_search = get_hybrid_search(
                    vector_store=vector_store,
                    embedder=embedder,
                )
            except Exception as e:
                logger.warning(
                    "Failed to initialize hybrid search, using text-only",
                    extra={"error": str(e)}
                )
                self._hybrid_search = HybridSearch()
        return self._hybrid_search
    
    def _get_structured_planner(self) -> StructuredPlanner:
        """Get or create structured planner instance."""
        if self._structured_planner is None:
            self._structured_planner = StructuredPlanner(
                llm_router=self._llm_router,
                skill_registry=self._skill_registry,
            )
        return self._structured_planner
    
    def _search_relevant_memory(
        self,
        query: str,
        limit: int | None = None,
        min_score: float | None = None,
    ) -> list[str]:
        """Search for relevant memory entries based on query.
        
        Uses hybrid search (vector + text) to find relevant memories.
        
        Args:
            query: User's question/message
            limit: Maximum number of results (default from config)
            min_score: Minimum relevance score filter (default from config)
            
        Returns:
            List of relevant memory content strings
        """
        try:
            # Load defaults from config
            try:
                from ..config import get_config
                config = get_config()
                if limit is None:
                    limit = config.search.limit
                if min_score is None:
                    min_score = config.search.min_score
            except Exception:
                limit = limit or 10
                min_score = min_score or 0.0
            
            hybrid_search = self._get_hybrid_search()
            md_sync = get_md_sync(str(self.workspace_path))
            
            # Get all entries for searching (consistent with API endpoint)
            entries = md_sync.list_all_entries(limit=1000)
            
            if not entries:
                return []
            
            # Perform hybrid search (same params as /api/v1/memory/search)
            results = hybrid_search.search(
                query=query,
                entries=entries,
                limit=limit,
                offset=0,
                min_score=min_score,
            )
            
            # Extract content from results
            relevant_memories = []
            for result in results:
                if result.entry and result.entry.content:
                    # Include score for context
                    relevant_memories.append(
                        f"[Áõ∏ÂÖ≥Â∫¶:{result.score:.2f}] {result.entry.content[:200]}"
                    )
            
            logger.info(
                "Memory search completed",
                extra={
                    "query": query[:50],
                    "results_count": len(relevant_memories),
                }
            )
            
            return relevant_memories
            
        except Exception as e:
            logger.warning(
                "Memory search failed",
                extra={"error": str(e)}
            )
            return []
    
    def _register_builtin_tools(self) -> None:
        """Register built-in tools."""
        for tool in get_builtin_tools():
            self._tool_manager.register(tool)
    
    def _is_tool_confirmation_message(self, message: str) -> bool:
        """Detect if a message is a tool confirmation result.
        
        Tool confirmation messages have the format:
        "[Áî®Êà∑Â∑≤Á°ÆËÆ§ÊâßË°åÈ´òÂç±ÂëΩ‰ª§]\nÂëΩ‰ª§Ôºö{command}\nÊâßË°åÁªìÊûúÔºöÊàêÂäü/Â§±Ë¥•"
        
        Args:
            message: The user message to check
            
        Returns:
            True if this is a tool confirmation result message
        """
        return "[Áî®Êà∑Â∑≤Á°ÆËÆ§ÊâßË°åÈ´òÂç±ÂëΩ‰ª§]" in message or "[Áî®Êà∑Â∑≤Á°ÆËÆ§" in message
    
    def register_tool(self, tool: Any) -> None:
        """Register a custom tool."""
        self._tool_manager.register(tool)
    
    async def process_request(
        self,
        session_id: str,
        user_message: str,
        session_type: SessionType | str = SessionType.MAIN,
        stream: bool = True,
    ) -> AsyncGenerator[dict[str, Any], None]:
        """Process a user request."""
        start_time = time.time()
        
        if isinstance(session_type, str):
            session_type = SessionType(session_type)
        
        logger.info(
            "Processing request",
            extra={
                "session_id": session_id,
                "session_type": session_type.value,
                "message_length": len(user_message),
                "user_message_preview": user_message[:100] if len(user_message) > 100 else user_message,
            }
        )
        
        # ===== CRITICAL DEBUG LOGS =====
        logger.info(f"[PROCESS_REQUEST_START] session={session_id}, message={user_message[:100]}")
        
        # üî• FIX: Detect if this is a tool confirmation result message
        # If so, we should inherit the Plan from the parent trace/session context
        is_tool_confirmation = self._is_tool_confirmation_message(user_message)
        if is_tool_confirmation:
            logger.info(
                "Tool confirmation result detected, will attempt to inherit Plan state",
                extra={"session_id": session_id}
            )
            
            # üî• FIX: Try to restore PlanState from cache or file
            cached_plan_state = None
            
            # First try memory cache
            if session_id in self._plan_state_cache:
                cached_plan_state = self._plan_state_cache[session_id]
                logger.info(
                    "Restored PlanState from memory cache",
                    extra={
                        "session_id": session_id,
                        "current_step": cached_plan_state.current_step,
                    }
                )
            # Then try file persistence
            else:
                cached_plan_state = self._plan_persistence.load_plan(session_id)
                if cached_plan_state:
                    # Also save to memory cache for faster access
                    self._plan_state_cache[session_id] = cached_plan_state
                    logger.info(
                        "Restored PlanState from file",
                        extra={
                            "session_id": session_id,
                            "current_step": cached_plan_state.current_step,
                        }
                    )
            
            # Use restored plan state if available
            if cached_plan_state:
                logger.info(
                    "Plan state restored successfully",
                    extra={
                        "session_id": session_id,
                        "steps_count": len(cached_plan_state.structured_plan.steps) if cached_plan_state.structured_plan else 0,
                        "current_step": cached_plan_state.current_step,
                    }
                )
                
                # Restore the tool validator with the cached plan
                if cached_plan_state.structured_plan:
                    self._tool_validator = ToolConstraintValidator(cached_plan_state.structured_plan)
                    
                    # Also restore the current step index
                    if hasattr(self._tool_validator, 'current_step_index'):
                        # Find the next incomplete step
                        for i, step in enumerate(cached_plan_state.structured_plan.steps):
                            step_status = cached_plan_state.get_step_status(step.id)
                            if step_status != 'completed':
                                self._tool_validator.current_step_index = i
                                logger.info(
                                    "Restored current_step_index from cached plan state",
                                    extra={
                                        "current_step_index": i,
                                        "step_id": step.id,
                                        "step_name": step.name,
                                    }
                                )
                                break
        
        # Step 0: Task Analysis (hybrid: LLM-assisted + rule-based fallback)
        logger.info(f"[TASK_ANALYSIS_START] Analyzing message: {user_message[:50]}...")
        analysis = await self._task_analyzer.analyze(user_message)
        
        # üî• FIX: Override needs_plan for tool confirmation messages
        # Even if TaskAnalyzer thinks it's simple, we need to continue the existing Plan
        if is_tool_confirmation:
            original_needs_plan = analysis.needs_plan
            
            # üî• NEW: Check if there's an existing plan in cache
            # If yes, keep using plan constraints (don't set needs_plan=False)
            # If no, and has complex requirements (like PDF), generate new plan
            has_existing_plan = session_id in self._plan_state_cache
            has_pdf_need = any(kw in user_message.lower() for kw in ["pdf", "PDF", "ÁîüÊàê pdf", "ÂàõÂª∫ pdf"])
            
            if has_existing_plan:
                # Keep original needs_plan value to continue using plan constraints
                logger.info(
                    "Tool confirmation with existing plan - will continue following plan steps",
                    extra={
                        "session_id": session_id,
                        "has_existing_plan": True,
                        "original_needs_plan": original_needs_plan,
                    }
                )
            elif has_pdf_need:
                # Need to generate new plan for PDF creation
                analysis.needs_plan = True
                logger.info(
                    "Tool confirmation with PDF need - will generate new plan",
                    extra={
                        "session_id": session_id,
                        "has_pdf_need": True,
                        "overridden_needs_plan": True,
                    }
                )
            else:
                # Simple task confirmation, no plan needed
                analysis.needs_plan = False
                logger.info(
                    "Simple tool confirmation - no plan needed",
                    extra={
                        "session_id": session_id,
                        "overridden_needs_plan": False,
                    }
                )
        
        logger.info(f"[TASK_ANALYSIS_DONE] complexity={analysis.complexity}, needs_plan={analysis.needs_plan}, matched_skills={analysis.matched_skills}")
        logger.info(
            "Task analysis completed",
            extra={
                "session_id": session_id,
                "complexity": analysis.complexity,
                "confidence": analysis.confidence,
                "needs_plan": analysis.needs_plan,
                "indicators": analysis.indicators,
                "matched_skills": [s["name"] for s in analysis.matched_skills] if analysis.matched_skills else [],
                "recommended_skill": analysis.recommended_skill["name"] if analysis.recommended_skill else None,
            }
        )
        yield {
            "type": ORCH_EVENT_TASK_ANALYSIS,
            "complexity": analysis.complexity,
            "needs_plan": analysis.needs_plan,
            "matched_skills": analysis.matched_skills,
            "recommended_skill": analysis.recommended_skill,
        }
        
        # Step 0.5: Parse Skill Command (Phase 2 - Argument Passing)
        logger.info(f"[SKILL_PARSE_START] Parsing skill command from: {user_message[:50]}...")
        
        # Try exact /command format first
        skill_name, arguments = TaskAnalyzer.parse_skill_command(user_message)
        
        # If not /command format, try fuzzy matching with skill names
        if not skill_name:
            # Get available skills from registry cache
            all_skills = self._skill_registry.list_all_skills()
            if all_skills:
                available_skills = [skill.name for skill in all_skills]
                extracted_skill, remaining_msg = TaskAnalyzer.extract_skill_name(user_message, available_skills)
                if extracted_skill:
                    skill_name = extracted_skill
                    arguments = remaining_msg
                    logger.info(
                        "Skill name detected via fuzzy matching (without slash)",
                        extra={
                            "skill_name": skill_name,
                            "arguments": arguments,
                        }
                    )
        
        logger.info(f"[SKILL_PARSE_RESULT] skill_name={skill_name}, arguments={arguments}")
        
        if skill_name:
            logger.info(
                "Skill command detected",
                extra={
                    "session_id": session_id,
                    "skill_name": skill_name,
                    "arguments": arguments,
                }
            )
            
            # ===== FAST PATH: Direct skill execution =====
            # If user explicitly invoked a skill with /command, skip complex planning
            # and execute directly using the skill's CLI binding
            # Note: Only trigger FAST PATH for simple CLI commands, not natural language
            if skill_name and arguments:
                # Check if arguments look like natural language (need semantic understanding)
                # If so, fall through to ReAct loop for proper interpretation
                # CRITICAL: Must distinguish between CLI commands and natural language
                
                # CLI command patterns (NOT natural language)
                cli_command_patterns = [
                    r'^open\s+https?://',      # open https://example.com
                    r'^open\s+www\.',          # open www.example.com
                    r'^open\s+[a-z0-9.-]+\.',  # open example.com (domain pattern)
                    r'^get\s+text\s+',         # get text <selector>
                    r'^click\s+',              # click <selector>
                    r'^screenshot',            # screenshot
                    r'^close',                 # close
                    r'^fill\s+',               # fill <selector> <value>
                    r'^type\s+',               # type <selector> <value>
                    r'^navigate',              # navigate
                    r'^back',                  # back
                    r'^forward',               # forward
                    r'^reload',                # reload
                    r'^snapshot',              # snapshot
                ]
                
                is_cli_command = any(re.match(pattern, arguments.strip()) for pattern in cli_command_patterns)
                
                # Natural language indicators
                natural_language_indicators = [
                    'Â∏ÆÊàë', 'ËØ∑', 'ÊÉ≥Ë¶Å', 'ÈúÄË¶Å',  # Request indicators
                    'Ëé∑Âèñ.*ÂÜÖÂÆπ', 'ÊâìÂºÄ.*ÁΩëÈ°µ', 'ÁÇπÂáª.*ÊåâÈíÆ',  # Chinese verb-object phrases
                    'ÊêúÁ¥¢', 'Âπ∂', 'ÁÑ∂Âêé', 'ÊúÄÂêé',  # Multi-step indicators
                    'Êï∞ÊçÆ', '‰ø°ÊÅØ', 'ÁªìÊûú',  # Data extraction indicators
                ]
                
                # Check if there's additional natural language after CLI command
                has_natural_language_suffix = False
                if is_cli_command:
                    # Try to detect if there's natural language after the CLI command
                    # e.g., "open www.baidu.com ÊêúÁ¥¢‰ªäÊó•Â§©Ê∞î" ‚Üí should use ReAct
                    cli_match = None
                    for pattern in cli_command_patterns:
                        match = re.match(pattern, arguments.strip())
                        if match:
                            cli_match = match
                            break
                    
                    if cli_match:
                        # Extract the part after the CLI command
                        remaining_text = arguments[cli_match.end():].strip()
                        if remaining_text:
                            # Check if remaining text contains natural language
                            has_natural_language_suffix = any(
                                indicator in remaining_text 
                                for indicator in natural_language_indicators
                            )
                            
                            if has_natural_language_suffix:
                                logger.info(
                                    "Natural language suffix detected after CLI command",
                                    extra={
                                        "skill_name": skill_name,
                                        "cli_command": arguments[:cli_match.end()],
                                        "natural_suffix": remaining_text,
                                    }
                                )
                
                is_natural_language = (
                    not is_cli_command and  # Not a CLI command
                    any(indicator in arguments for indicator in natural_language_indicators)
                ) or has_natural_language_suffix
                
                if is_natural_language:
                    logger.info(
                        "Natural language detected, using ReAct loop for interpretation",
                        extra={
                            "skill_name": skill_name,
                            "arguments": arguments,
                        }
                    )
                    # Fall through to normal ReAct path
                else:
                    # FAST PATH DISABLED: The hardcoded CLI command generation is unsafe
                    # Let ReAct Loop handle skill execution based on SKILL.md instructions
                    # Future: Implement proper CLI command parsing from SKILL.md metadata
                    logger.info(
                        "Skill command detected, using ReAct loop for safe execution",
                        extra={
                            "skill_name": skill_name if skill_name else "unknown",
                            "arguments": arguments,
                        }
                    )
                    # Fall through to ReAct Loop
            
            # Fall back to normal path for skills without scripts or complex tasks
            # Get skill metadata - CRITICAL DEBUG POINT
            logger.info(f"[SKILL_METADATA_START] Getting metadata for skill: {skill_name}")
            try:
                skill = self._skill_registry.get_skill_metadata(skill_name)
                logger.info(f"[SKILL_METADATA_RESULT] skill type={type(skill).__name__}, has_scripts={skill.has_scripts if skill else None}")
            except Exception as e:
                logger.error(f"[SKILL_METADATA_ERROR] Failed to get skill metadata: {e}", exc_info=True)
                raise
            
            if skill:
                # Phase 2: Set current skill context for tool restrictions
                self._current_skill_context = skill
                
                # Debug: Check skill attributes
                logger.info(f"[SKILL_CHECK] skill.name={skill.name}, type(skill.description)={type(skill.description).__name__}, skill.description={skill.description[:50] if skill.description else None}...")
                logger.info(f"[SKILL_CHECK] skill.has_scripts={skill.has_scripts}, skill.allowed_tools={skill.allowed_tools}, skill.argument_hint={skill.argument_hint}")
                
                logger.info(
                    f"Skill '{skill_name}' loaded",
                    extra={
                        "session_id": session_id,
                        "has_scripts": skill.has_scripts,
                        "allowed_tools": skill.allowed_tools,
                        "argument_hint": skill.argument_hint,
                    }
                )
                
                # Add skill context to messages
                messages = []  # Initialize messages list for building message history
                skill_context_msg = {
                    "role": "system",
                    "content": (
                        f"üîß **Skill Invocation: {skill_name}**\n\n"
                        f"**Description**: {skill.description}\n"
                        f"**Arguments**: {arguments if arguments else '(none)'}\n"
                        f"**Available Scripts**: {'Yes' if skill.has_scripts else 'No'}\n\n"
                        f"You are now executing the '{skill_name}' skill. "
                        f"Follow the guidelines in this skill's SKILL.md and use the provided arguments.\n\n"
                    )
                }
                
                # Add CLI command format guidance for skills with run_in_terminal
                if 'run_in_terminal' in (skill.allowed_tools or []):
                    cli_guidance_msg = {
                        "role": "system",
                        "content": (
                            f"‚ö° **CLI Command Format Important**:\n\n"
                            f"The argument `{arguments}` starts with a CLI command pattern.\n"
                            f"Use the appropriate CLI tool for this skill as documented in its SKILL.md file.\n\n"
                            f"**Available Commands**: Refer to the skill's documentation for exact command format.\n\n"
                            f"---\n"
                        )
                    }
                    # Insert after skill_context_msg
                    messages.insert(len(messages), cli_guidance_msg)
            else:
                logger.warning(
                    f"Skill '{skill_name}' not found in registry",
                    extra={"session_id": session_id}
                )
                skill_context_msg = {
                    "role": "system",
                    "content": (
                        f"‚ö†Ô∏è **Unknown Skill: {skill_name}**\n\n"
                        f"The skill '{skill_name}' was not found in the skill registry. "
                        f"Please check the skill name and try again.\n\n"
                        f"---\n"
                    )
                }
        else:
            skill_context_msg = None
            # Clear skill context for non-skill commands
            self._current_skill_context = None
        
        # Step 1: Policy Reload
        policy, reloaded = self.policy_engine.reload_if_changed()
        yield {
            "type": ORCH_EVENT_POLICY,
            "reloaded": reloaded,
            "policy_hash": policy.source_hash[:8],
        }
        
        # Step 2: Session Rules
        session_rules = self.session_guard.apply_rules(
            session_type,
            policy.hard_constraints,
        )
        
        # Step 3: Load Context
        try:
            context = self._load_context(session_type, session_rules)
            yield {
                "type": ORCH_EVENT_CONTEXT,
                "has_spirit": context.spirit is not None,
                "has_owner": context.owner is not None,
                "tools_count": len(context.tools),
            }
        except Exception as e:
            yield {
                "type": ORCH_EVENT_ERROR,
                "error": f"Failed to load context: {str(e)}",
            }
            return
        
        # Step 3.5: Search Relevant Memory (before reasoning)
        relevant_memories = self._search_relevant_memory(user_message, limit=5)
        if relevant_memories:
            logger.info(
                "Relevant memories retrieved",
                extra={
                    "session_id": session_id,
                    "memories_count": len(relevant_memories),
                }
            )
        
        # Step 3.6: Generate Plan (if needed)
        plan_state: PlanState | None = None
        structured_plan: StructuredPlan | None = None
        
        if analysis.needs_plan:
            try:
                # üî• DEBUG: Log entry point
                logger.info(
                    "Attempting plan generation",
                    extra={
                        "session_id": session_id,
                        "needs_plan": analysis.needs_plan,
                        "skill_name": skill_name,
                        "matched_skills_count": len(analysis.matched_skills) if hasattr(analysis, 'matched_skills') else 0,
                    }
                )
                
                # Check if skill is specified - use Structured Planner v2.0
                if skill_name and analysis.matched_skills:
                    logger.info(
                        "Using StructuredPlanner v2.0 for skill-based task",
                        extra={
                            "session_id": session_id,
                            "skill_name": skill_name,
                        }
                    )
                    structured_planner = self._get_structured_planner()
                    structured_plan = await structured_planner.generate(
                        goal=user_message,
                        skill_name=skill_name,
                        workspace_path=str(self.workspace_path),  # üî• NEW: Pass workspace path
                    )
                    
                    # Initialize validators
                    self._tool_validator = ToolConstraintValidator(structured_plan)
                    self._milestone_validator = MilestoneValidator(structured_plan)
                    
                    # Convert to PlanState for backward compatibility
                    plan_text = structured_plan.to_prompt()
                    plan_state = PlanState(
                        original_plan=plan_text,
                        current_step=1,
                        total_steps=len(structured_plan.steps),
                        completed_steps=[],
                        failed_count=0,
                        last_adjustment=None,
                        structured_plan=structured_plan,  # Store reference
                    )
                    
                    logger.info(
                        "StructuredPlan v2.0 generated",
                        extra={
                            "session_id": session_id,
                            "skill_binding": structured_plan.skill_binding,
                            "tool_constraints": structured_plan.tool_constraints,
                            "steps_count": len(structured_plan.steps),
                            "milestones_count": len(structured_plan.milestones),
                        }
                    )
                
                # ‚úÖ Áªü‰∏Ä‰ΩøÁî® StructuredPlannerÔºåÁßªÈô§ LightPlanner fallback
                structured_planner = self._get_structured_planner()
                structured_plan = await structured_planner.generate(
                    goal=user_message,
                    skill_name=skill_name,
                    workspace_path=str(self.workspace_path),  # üî• NEW: Pass workspace path
                )
                plan_text = structured_plan.to_prompt()
                plan_state = PlanState(
                    original_plan=plan_text,
                    current_step=1,
                    total_steps=len(structured_plan.steps),
                    completed_steps=[],
                    failed_count=0,
                    last_adjustment=None,
                    structured_plan=structured_plan,  # ‚úÖ Store reference for tool constraints
                )
                logger.info(
                    "StructuredPlan v2.0 generated",
                    extra={
                        "session_id": session_id,
                        "skill_binding": structured_plan.skill_binding,
                        "tool_constraints": structured_plan.tool_constraints,
                        "steps_count": len(structured_plan.steps),
                        "milestones_count": len(structured_plan.milestones),
                    }
                )
                
                yield {
                    "type": ORCH_EVENT_PLAN_GENERATED,
                    "plan": plan_text,
                    "is_structured": structured_plan is not None,
                }
                
                # üî• FIX: Cache the PlanState for future tool confirmations
                self._plan_state_cache[session_id] = plan_state
                logger.info(
                    "Cached PlanState for session",
                    extra={
                        "session_id": session_id,
                        "steps_count": len(structured_plan.steps) if structured_plan else 0,
                    }
                )
                
                # üî• NEW: Save PlanState to file for persistence across restarts
                try:
                    saved = self._plan_persistence.save_plan(session_id, plan_state)
                    if saved:
                        logger.info(
                            "Plan saved to file",
                            extra={
                                "session_id": session_id,
                                "workspace": str(self.workspace_path),
                            }
                        )
                except Exception as e:
                    logger.warning(
                        "Failed to save plan to file, continuing with memory cache only",
                        extra={"session_id": session_id, "error": str(e)}
                    )
            except Exception as e:
                import traceback
                tb_str = traceback.format_exc()
                logger.error(
                    "Plan generation failed with KeyError",
                    extra={
                        "session_id": session_id,
                        "error": str(e),
                        "error_type": type(e).__name__,
                        "traceback_lines": tb_str.split('\n'),
                    }
                )
                logger.warning(
                    "Plan generation failed, continuing without plan",
                    extra={
                        "session_id": session_id,
                        "error": str(e),
                    }
                )
        
        # Step 4: Build Messages (with session history and compression)
        messages, compression_info = await self._build_messages(
            context, user_message, policy, relevant_memories, session_id, plan_state, skill_context_msg
        )
        
        # Yield compression status event for frontend debugging
        yield {
            "type": "compression_status",
            "session_id": session_id,
            "message_count": compression_info.get("message_count", 0),
            "token_count": compression_info.get("token_count", 0),
            "threshold_rounds": compression_info.get("threshold_rounds"),
            "threshold_tokens": compression_info.get("threshold_tokens"),
            "needs_compression": compression_info.get("needs_compression", False),
            "compressed": compression_info.get("compressed", False),
        }
        
        # Step 5: ReAct Loop
        final_response = ""
        
        try:
            async for event in self._react_loop.run_streaming(
                messages,
                tools=self._tool_manager.get_all_tools(),
                session_id=session_id,
                skill_context=self._current_skill_context,  # Phase 2 - Pass skill context for tool restrictions
                plan_state=plan_state,  # NEW: Pass plan state for structured plan tool constraints
            ):
                event_type = event.get("type")
                
                # Debug: log all events
                logger.info(
                    "Processing event in engine",
                    extra={
                        "event_type": event_type,
                        "event_keys": list(event.keys()),
                        "tool_call_id_in_event": event.get("tool_call_id"),
                    }
                )
                
                if event_type == REACT_EVENT_THINKING:
                    yield {
                        "type": ORCH_EVENT_THINKING,
                        "content": event.get("content", ""),
                    }
                elif event_type == "tool_call":
                    tool_call_id = event.get("tool_call_id")
                    tool_name = event.get("name")
                    
                    # ===== StructuredPlan v2.0: Tool Constraint Validation =====
                    if self._tool_validator and hasattr(self._tool_validator, 'plan'):
                        is_allowed, reason = self._tool_validator.is_tool_allowed(tool_name)
                        
                        if not is_allowed:
                            logger.warning(
                                "Tool constraint violation detected",
                                extra={
                                    "session_id": session_id,
                                    "tool_name": tool_name,
                                    "reason": reason,
                                    "violation_count": self._tool_validator.violation_count,
                                }
                            )
                            
                            # Emit error event to inform LLM
                            yield {
                                "type": ORCH_EVENT_ERROR,
                                "error": f"Â∑•ÂÖ∑‰ΩøÁî®ÈôêÂà∂Ôºö{reason}",
                            }
                            
                            # Check if we should trigger replan
                            if self._tool_validator.should_trigger_replan():
                                logger.info(
                                    "Replan triggered due to repeated tool constraint violations",
                                    extra={
                                        "session_id": session_id,
                                        "violation_count": self._tool_validator.violation_count,
                                    }
                                )
                                yield {
                                    "type": ORCH_EVENT_PLAN_ADJUSTMENT,
                                    "reason": f"LLM Â§öÊ¨°ËøùÂèçÂ∑•ÂÖ∑Á∫¶ÊùüÔºà{self._tool_validator.violation_count}Ê¨°ËøùËßÑÔºâ",
                                }
                            
                            # Skip this tool call - continue to next iteration
                            continue
                    
                    logger.info(
                        "Emitting tool_call event",
                        extra={
                            "tool_call_id": tool_call_id,
                            "name": tool_name,
                            "raw_event_keys": list(event.keys()),
                        }
                    )
                    yield {
                        "type": ORCH_EVENT_TOOL_CALL,
                        "tool_call_id": tool_call_id,
                        "name": tool_name,
                        "arguments": event.get("arguments"),
                    }
                elif event_type == "tool_result":
                    result = event.get("result", {})
                    tool_call_id = event.get("tool_call_id")
                    tool_name = event.get("tool_name")
                    success = event.get("success")
                    output = event.get("output", "")
                    
                    # Update plan state if we have a plan
                    if plan_state:
                        self._plan_context.update_from_tool_result(
                            plan_state,
                            tool_name=tool_name,
                            success=success,
                            output=output,
                        )
                        
                        # ‚úÖ Êñ∞Â¢ûÔºöÊõ¥Êñ∞ÂΩìÂâçÊ≠•È™§Á¥¢ÂºïÔºàÂ¶ÇÊûúÂ∑•ÂÖ∑ÊâßË°åÊàêÂäüÔºâ
                        if success and self._tool_validator and hasattr(self._tool_validator, 'update_current_step'):
                            logger.debug(
                                "Attempting to update step index",
                                extra={
                                    "tool_name": tool_name,
                                    "has_plan": bool(plan_state.structured_plan),
                                    "steps_count": len(plan_state.structured_plan.steps) if plan_state.structured_plan else 0,
                                }
                            )
                            # ÊâæÂà∞ÂØπÂ∫îÁöÑÊ≠•È™§ ID Âπ∂Êõ¥Êñ∞
                            if plan_state.structured_plan:
                                for step in plan_state.structured_plan.steps:
                                    if step.tool == tool_name:
                                        logger.info(
                                            "Found matching step, updating index",
                                            extra={
                                                "step_id": step.id,
                                                "step_name": step.name,
                                                "tool_name": tool_name,
                                            }
                                        )
                                        self._tool_validator.update_current_step(step.id)
                                        break
                        
                        # ===== StructuredPlan v2.0: Milestone Validation =====
                        if self._milestone_validator and hasattr(self._milestone_validator, 'plan'):
                            try:
                                # Use new MilestoneValidator for structured plans
                                validation_passed, validation_msg = self._milestone_validator.check_and_advance(
                                    tool_name=tool_name,
                                    success=success,
                                    output=output,
                                )
                                
                                if validation_passed:
                                    logger.info(
                                        "Milestone validation passed",
                                        extra={
                                            "session_id": session_id,
                                            "message": validation_msg,
                                            "current_step": self._milestone_validator.current_step_index + 1,
                                            "total_steps": len(self._milestone_validator.plan.steps),
                                        }
                                    )
                                else:
                                    logger.warning(
                                        "Milestone validation failed",
                                        extra={
                                            "session_id": session_id,
                                            "reason": validation_msg,
                                        }
                                    )
                                    plan_state.failed_count += 1
                            except Exception as e:
                                logger.warning(
                                    "MilestoneValidator error, falling back to PlanContext validation",
                                    extra={"error": str(e)}
                                )
                                # Fallback to old PlanContext validation
                                current_step_desc = self._get_current_step_description(plan_state)
                                if current_step_desc and self._plan_context.should_validate_milestone(current_step_desc):
                                    validation_context = self._build_validation_context(tool_name, output)
                                    passed, msg = self._plan_context.validate_milestone(
                                        plan_state,
                                        milestone_name=current_step_desc,
                                        context=validation_context,
                                    )
                                    
                                    if not passed:
                                        logger.warning(
                                            "Milestone validation failed (fallback)",
                                            extra={
                                                "session_id": session_id,
                                                "milestone": current_step_desc,
                                                "reason": msg,
                                            }
                                        )
                                        plan_state.failed_count += 1
                        else:
                            # Fallback to old PlanContext validation for v1.0 plans
                            current_step_desc = self._get_current_step_description(plan_state)
                            if current_step_desc and self._plan_context.should_validate_milestone(current_step_desc):
                                validation_context = self._build_validation_context(tool_name, output)
                                passed, msg = self._plan_context.validate_milestone(
                                    plan_state,
                                    milestone_name=current_step_desc,
                                    context=validation_context,
                                )
                                
                                if not passed:
                                    logger.warning(
                                        "Milestone validation failed",
                                        extra={
                                            "session_id": session_id,
                                            "milestone": current_step_desc,
                                            "reason": msg,
                                        }
                                    )
                                    # Mark as failure to trigger replan if needed
                                    plan_state.failed_count += 1
                        
                        # Check if we need to re-plan
                        need_replan, reason = self._plan_context.should_replan(plan_state)
                        if need_replan:
                            # Record the replan and check if we can still replan
                            self._plan_context.record_replan(plan_state, reason)
                            
                            if plan_state.replan_count > self._plan_context.MAX_REPLAN_COUNT:
                                logger.warning(
                                    "Replan limit exceeded",
                                    extra={
                                        "session_id": session_id,
                                        "replan_count": plan_state.replan_count,
                                    }
                                )
                            else:
                                logger.info(
                                    "Plan adjustment triggered",
                                    extra={
                                        "session_id": session_id,
                                        "reason": reason,
                                        "replan_count": plan_state.replan_count,
                                    }
                                )
                                yield {
                                    "type": ORCH_EVENT_PLAN_ADJUSTMENT,
                                    "reason": reason,
                                }
                    
                    logger.info(
                        "Emitting tool_result event",
                        extra={
                            "tool_call_id": tool_call_id,
                            "tool_name": tool_name,
                            "success": success,
                            "has_result": bool(result),
                            "result_requires_confirmation": result.get("requires_confirmation") if result else None,
                        }
                    )
                    yield {
                        "type": ORCH_EVENT_TOOL_RESULT,
                        "tool_call_id": tool_call_id,
                        "tool_name": tool_name,
                        "success": success,
                        "output": output,
                        "result": result,
                    }
                elif event_type == REACT_EVENT_FINAL:
                    # üîç CRITICAL DEBUG: Log final_answer event details
                    logger.info(
                        "üî¥ FINAL_ANSWER received from ReAct Loop",
                        extra={
                            "session_id": session_id,
                            "content_length": len(event.get("content", "")),
                            "content_preview": str(event.get("content", ""))[:200],
                        }
                    )
                    
                    final_response = event.get("content", "")
                    final_response = self.response_guard.process(
                        final_response,
                        policy.soft_guidelines,
                    )
                    
                    # üîç CRITICAL DEBUG: Log after processing
                    logger.info(
                        "üü¢ FINAL_ANSWER forwarded to WebSocket",
                        extra={
                            "session_id": session_id,
                            "final_response_length": len(final_response),
                        }
                    )
                    
                    yield {
                        "type": ORCH_EVENT_FINAL,
                        "content": final_response,
                    }
                elif event_type == "awaiting_confirmation":
                    # Forward the awaiting confirmation event to frontend
                    yield {
                        "type": "awaiting_confirmation",
                        "tool_call_id": event.get("tool_call_id"),
                        "confirmation_id": event.get("confirmation_id"),
                        "command": event.get("command"),
                    }
                elif event_type == REACT_EVENT_ERROR:
                    error_msg = event.get("error", "Unknown error")
                    
                    # Check if max iterations reached - trigger Plan Mode
                    if "Maximum iterations" in error_msg:
                        # Check if we've already replanned too many times
                        if plan_state and plan_state.replan_count >= self._plan_context.MAX_REPLAN_COUNT:
                            logger.warning(
                                "Max iterations reached but replan limit exceeded",
                                extra={
                                    "session_id": session_id,
                                    "replan_count": plan_state.replan_count,
                                }
                            )
                            yield {
                                "type": ORCH_EVENT_ERROR,
                                "error": f"{error_msg} (Â∑≤Â∞ùËØïÈáçËßÑÂàí {plan_state.replan_count} Ê¨°ÔºåËØ∑Â∞ùËØïÁÆÄÂåñ‰ªªÂä°ÊàñÊèê‰æõÊõ¥Â§ö‰ø°ÊÅØ)",
                            }
                            continue
                        
                        logger.info(
                            "Max iterations reached, switching to Plan Mode",
                            extra={"session_id": session_id}
                        )
                        yield {
                            "type": ORCH_EVENT_PLAN_ADJUSTMENT,
                            "reason": "max_iterations_reached",
                        }
                        # Generate plan and continue execution with plan injection
                        try:
                            structured_planner = self._get_structured_planner()
                            structured_plan = await structured_planner.generate(
                                goal=user_message,
                                skill_name=skill_name,
                                workspace_path=str(self.workspace_path),  # üî• FIX: Pass workspace path
                            )
                            plan_text = structured_plan.to_prompt()
                            
                            # Create or update plan state
                            if plan_state:
                                self._plan_context.record_replan(plan_state, "max_iterations_reached")
                                plan_state.original_plan = plan_text
                                plan_state.total_steps = plan_text.count("\n") + 1
                            else:
                                plan_state = PlanState(
                                    original_plan=plan_text,
                                    current_step=1,
                                    total_steps=plan_text.count("\n") + 1,
                                    completed_steps=[],
                                    failed_count=0,
                                    last_adjustment=None,
                                    replan_count=0,
                                )
                            
                            logger.info(
                                "Plan generated after max iterations",
                                extra={
                                    "session_id": session_id,
                                    "plan_steps": plan_state.total_steps,
                                    "replan_count": plan_state.replan_count,
                                }
                            )
                            yield {
                                "type": ORCH_EVENT_PLAN_GENERATED,
                                "plan": plan_text,
                            }
                            
                            # Continue execution with plan injected into system prompt
                            logger.info(
                                "Continuing execution with plan injection",
                                extra={
                                    "session_id": session_id,
                                    "current_step": plan_state.current_step,
                                }
                            )
                            
                            # Build messages with plan state (plan will be injected into system prompt)
                            messages, debug_info = await self._build_messages(
                                context=context,
                                user_message=user_message,
                                policy=policy,
                                relevant_memories=relevant_memories,
                                session_id=session_id,
                                plan_state=plan_state,
                                skill_context_msg=skill_context_msg,
                            )
                            
                            # ‚úÖ OPTIMIZE: Temporarily increase max_iterations for Plan Mode execution (reduced from 10 to 7)
                            original_max_iterations = self._react_loop.max_iterations
                            self._react_loop.max_iterations = 7  # Limited iterations for plan execution
                            
                            # ‚úÖ OPTIMIZE: Initialize Plan Mode monitor for emergency braking
                            self._plan_monitor = PlanModeMonitor(
                                max_reflections=3,
                                max_same_step_iterations=5,
                                max_execution_time_seconds=60,
                            )
                            logger.info(
                                "Plan Mode monitor initialized",
                                extra={
                                    "session_id": session_id,
                                    "max_reflections": 3,
                                    "max_same_step_iterations": 5,
                                }
                            )
                            
                            try:
                                # Call LLM again with plan-injected system prompt and run ReAct loop
                                async for event in self._react_loop.run_streaming(
                                    messages,
                                    tools=self._tool_manager.get_all_tools(),
                                    session_id=session_id,
                                    skill_context=self._current_skill_context,  # Phase 2
                                    plan_state=plan_state,  # NEW: Pass plan state for tool constraints
                                ):
                                    event_type = event.get("type")
                                    
                                    # üîç CRITICAL DEBUG: Log ALL events from Plan Mode ReAct Loop
                                    logger.info(
                                        "üîç Plan Mode ReAct Loop event",
                                        extra={
                                            "session_id": session_id,
                                            "event_type": event_type,
                                            "event_keys": list(event.keys()),
                                            "content_preview": str(event.get("content", ""))[:100] if event.get("content") else None,
                                        }
                                    )
                                    
                                    if event_type == REACT_EVENT_THINKING:
                                        yield {
                                            "type": ORCH_EVENT_THINKING,
                                            "content": event.get("content", ""),
                                        }
                                    elif event_type == "tool_call":
                                        tool_call_id = event.get("tool_call_id")
                                        tool_name = event.get("name")
                                        arguments = event.get("arguments", {})
                                        
                                        # ‚úÖ FIX: Validate and correct tool parameters
                                        if arguments and isinstance(arguments, dict):
                                            # Fix known parameter mismatches
                                            corrected_args = self._correct_tool_parameters(tool_name, arguments)
                                            if corrected_args != arguments:
                                                logger.info(
                                                    "Tool parameters corrected",
                                                    extra={
                                                        "session_id": session_id,
                                                        "tool_name": tool_name,
                                                        "original_keys": list(arguments.keys()),
                                                        "corrected_keys": list(corrected_args.keys()),
                                                    }
                                                )
                                                # Update event with corrected arguments
                                                event["arguments"] = corrected_args
                                            
                                        yield {
                                            "type": ORCH_EVENT_TOOL_CALL,
                                            "tool_call_id": tool_call_id,
                                            "name": tool_name,
                                            "arguments": event.get("arguments"),
                                        }
                                    elif event_type == "tool_result":
                                        yield {
                                            "type": ORCH_EVENT_TOOL_RESULT,
                                            "tool_call_id": event.get("tool_call_id"),
                                            "success": event.get("success"),
                                            "output": event.get("output", ""),
                                            "error": event.get("error"),
                                        }
                                        
                                        # ‚úÖ OPTIMIZE: Record tool call in monitor
                                        if self._plan_monitor:
                                            self._plan_monitor.record_tool_call(
                                                event.get("name", "unknown"),
                                                event.get("success", False)
                                            )
                                    
                                    elif event_type == REACT_EVENT_REFLECTION:
                                        # ‚úÖ OPTIMIZE: Check if we should abort via monitor
                                        if self._plan_monitor and plan_state:
                                            status = self._plan_monitor.record_reflection(plan_state)
                                            
                                            if status in [PlanModeStatus.ABORT_NO_PROGRESS, PlanModeStatus.ABORT_TIME_LIMIT]:
                                                # Emergency braking!
                                                logger.warning(
                                                    "Plan Mode emergency braking triggered",
                                                    extra={
                                                        "session_id": session_id,
                                                        "status": status.value,
                                                        "report": self._plan_monitor.get_status_report(),
                                                    }
                                                )
                                                
                                                # Yield error to user
                                                yield {
                                                    "type": ORCH_EVENT_ERROR,
                                                    "error": self._plan_monitor.create_abort_message(status),
                                                }
                                                
                                                # Break out of ReAct loop
                                                break
                                        
                                        # Forward reflection event
                                        yield {
                                            "type": ORCH_EVENT_CHUNK,
                                            "content": f"\n{event.get('content', '')}\n",
                                        }
                                
                                # Update final response (empty since we streamed events)
                                final_response = ""
                            
                            finally:
                                # Restore original max_iterations after Plan Mode execution
                                self._react_loop.max_iterations = original_max_iterations
                                logger.info(
                                    "Restored max_iterations after Plan Mode execution",
                                    extra={
                                        "session_id": session_id,
                                        "max_iterations": self._react_loop.max_iterations,
                                    }
                                )
                                
                                # ‚úÖ OPTIMIZE: Extract and record lesson learned if error was corrected
                                if hasattr(self, '_plan_monitor') and self._plan_monitor:
                                    try:
                                        from ..services.error_learning import get_error_learning_service
                                        
                                        error_learning_service = get_error_learning_service(self._llm_router)
                                        
                                        # Check if there were errors that got corrected
                                        report = self._plan_monitor.get_status_report()
                                        if report.get('failed_attempts', 0) > 0:
                                            # Extract lesson from the experience
                                            correction_summary = f"""Âú® Plan Mode ÊâßË°å‰∏≠ÈÅáÂà∞ÈîôËØØÂπ∂Â∞ùËØïÁ∫†Ê≠£Ôºö
- ÂèçÊÄùÊ¨°Êï∞Ôºö{report.get('reflection_count', 0)}
- Â§±Ë¥•Â∞ùËØïÔºö{report.get('failed_attempts', 0)}
- ÂΩìÂâçÊ≠•È™§ÔºöStep {report.get('current_step', 0)}
- Áä∂ÊÄÅÔºö{report.get('status', 'unknown')}"""
                                            
                                            logger.info(
                                                "Extracting lesson from Plan Mode error correction",
                                                extra={
                                                    "session_id": session_id,
                                                    "correction_summary": correction_summary,
                                                }
                                            )
                                    except Exception as e:
                                        logger.debug(
                                            "Failed to extract lesson from Plan Mode",
                                            extra={"error": str(e)}
                                        )
                        
                        except Exception as e:
                            logger.warning(
                                "Failed to generate plan after max iterations",
                                extra={"session_id": session_id, "error": str(e)}
                            )
                            yield {
                                "type": ORCH_EVENT_ERROR,
                                "error": f"ËÆ°ÂàíÁîüÊàêÂ§±Ë¥•Ôºö{str(e)}",
                            }
                    else:
                        yield {
                            "type": ORCH_EVENT_ERROR,
                            "error": error_msg,
                        }
        
        except Exception as e:
            yield {
                "type": ORCH_EVENT_ERROR,
                "error": str(e),
            }
            return
        
        # Step 6: Memory Writing
        if final_response:
            await self._write_memory(user_message, final_response, session_id)
        
        # üî• NEW: Clean up plan file after successful completion (optional)
        # Uncomment if you want to auto-delete plans after completion
        # try:
        #     self._plan_persistence.delete_plan(session_id)
        #     logger.info("Plan file cleaned up after completion", extra={"session_id": session_id})
        # except Exception as e:
        #     logger.warning(f"Failed to clean up plan file: {e}")
        
        # ===== SCHEME 3: Post-execution validation =====
        # Check if user request required file operations but none were detected
        if self._request_requires_file_creation(user_message):
            logger.info(
                "Post-execution validation: checking for file operations",
                extra={"session_id": session_id}
            )
            # Note: This is a placeholder for future implementation
            # In a full implementation, we would check the conversation history
            # to verify that appropriate tools were called
        
        # Log request completion with iteration statistics
        duration_ms = int((time.time() - start_time) * 1000)
        logger.info(
            "Request completed",
            extra={
                "session_id": session_id,
                "duration_ms": duration_ms,
                "trace_id": None,  # Will be filled by logging middleware if available
            }
        )
    
    def _request_requires_file_creation(self, user_message: str) -> bool:
        """Check if user message requires file creation operations.
        
        This is a helper method for post-execution validation.
        
        Args:
            user_message: Original user message
            
        Returns:
            True if the request likely requires file operations
        """
        import re
        
        # Patterns indicating file creation needs
        file_creation_patterns = [
            r'ÂàõÂª∫.*Êñá‰ª∂|create.*file|make.*file',
            r'ÂàõÂª∫.*PPT|create.*PPT|make.*presentation',
            r'ÂàõÂª∫.*ÊñáÊ°£ | create.*document',
            r'ÁîüÊàê.*Êä•Âëä | generate.*report',
            r'‰øùÂ≠ò.*Êñá‰ª∂|save.*file',
        ]
        
        message_lower = user_message.lower()
        for pattern in file_creation_patterns:
            if re.search(pattern, message_lower, re.IGNORECASE):
                return True
        
        return False
    
    def _load_context(self, session_type: SessionType, session_rules: dict) -> Any:
        """Load context from memory system."""
        context_builder = self._get_context_builder()
        context = context_builder.build_context()
        
        if not session_rules.get("load_memory_md", True):
            context.long_term_memory = ""
        
        return context
    
    async def _build_messages(
        self,
        context: Any,
        user_message: str,
        policy: Any,
        relevant_memories: list[str] | None = None,
        session_id: str | None = None,
        plan_state: PlanState | None = None,
        skill_context_msg: dict | None = None,
    ) -> tuple[list, dict]:
        """Build message list for LLM with session history and compression.
        
        REFACTORED: Now delegates to MessageBuilder component.
        
        Args:
            context: Loaded context bundle
            user_message: User's message
            policy: Policy bundle (not used anymore, kept for compatibility)
            relevant_memories: Retrieved relevant memories
            session_id: Session ID for loading conversation history
            plan_state: Current plan state
            skill_context_msg: Skill invocation context message
            
        Returns:
            Tuple of (messages list for LLM, compression info dict)
        """
        return await self._message_builder.build_messages(
            context=context,
            user_message=user_message,
            relevant_memories=relevant_memories,
            session_id=session_id,
            plan_state=plan_state,
            skill_context_msg=skill_context_msg,
            session_manager=self._get_session_manager(),
        )
    
        """Build message list for LLM with session history and compression.

        Args:
            context: Loaded context bundle
            user_message: User's message
            policy: Policy bundle
            relevant_memories: Retrieved relevant memories (from hybrid search)
            session_id: Session ID for loading conversation history
            plan_state: Current plan state (for plan mode)
            skill_context_msg: Skill invocation context message (Phase 2)

        Returns:
            Tuple of (messages list for LLM, compression info dict)
        """
        # ===== CRITICAL DEBUG LOGS =====
        logger.info(f"[BUILD_MESSAGES_START] context type={type(context).__name__}, skill_context_msg type={type(skill_context_msg).__name__ if skill_context_msg else None}")
        if skill_context_msg:
            logger.info(f"[BUILD_MESSAGES] skill_context_msg content preview: {skill_context_msg.get('content', '')[:100]}...")
        
        messages = []
        system_parts = []
        
        # Compression info to return for debugging
        compression_info = {
            "message_count": 0,
            "token_count": 0,
            "threshold_rounds": None,
            "threshold_tokens": None,
            "needs_compression": False,
            "compressed": False,
        }

        # Add soft guidelines from PolicyEngine (optimized version)
        # This avoids loading the entire AGENTS.md file in system prompt
        guidelines = self.policy_engine.build_system_prompt_guidelines()
        if guidelines:
            system_parts.append(guidelines)

        # Add identity
        if context.identity and context.identity.name:
            system_parts.append(f"\n# ‰Ω†ÁöÑË∫´‰ªΩ\n‰Ω†ÁöÑÂêçÂ≠óÊòØ„Äå{context.identity.name}„Äç„ÄÇ")

        # Add spirit
        if context.spirit:
            system_parts.append(f"\n# ËßíËâ≤ÂÆö‰Ωç\n‰Ω†ÊòØ{context.spirit.role}„ÄÇ")

        # Add owner
        if context.owner:
            system_parts.append(f"\n# Áî®Êà∑ÁîªÂÉè\nÂßìÂêç: {context.owner.name}")

        # Add tools
        tools = self._tool_manager.get_all_tools()
        if tools:
            tool_names = [t.name for t in tools]
            system_parts.append(f"\n# ÂèØÁî®Â∑•ÂÖ∑\n‰Ω†ÂèØ‰ª•‰ΩøÁî®‰ª•‰∏ãÂ∑•ÂÖ∑Ôºö{', '.join(tool_names)}")
            
            # ===== Add workspace path for file operations =====
            system_parts.append(
                f"\n\n# Â∑•‰ΩúÁõÆÂΩï‰∏éÊñá‰ª∂ÂàÜÁ±ªÂ≠òÂÇ®ÔºàÊûÅÂÖ∂ÈáçË¶ÅÔºâ\n"
                f"**‰Ω†ÁöÑÂ∑•‰ΩúÁõÆÂΩïÊòØÔºö** `{self.workspace_path}`\n\n"
                f"**Êñá‰ª∂ÂàÜÁ±ªÂ≠òÂÇ®ËßÑÂàôÔºàÂøÖÈ°ªÈÅµÂÆàÔºâÔºö**\n"
                f"| Êñá‰ª∂Á±ªÂûã | Â≠òÂÇ®ÁõÆÂΩï | Á§∫‰æãË∑ØÂæÑ |\n"
                f"|---------|---------|--------|\n"
                f"| Python/JS ËÑöÊú¨ | `scripts/` | `{self.workspace_path}/scripts/demo.py` |\n"
                f"| PPT ÊºîÁ§∫ÊñáÁ®ø | `presentations/` | `{self.workspace_path}/presentations/demo.pptx` |\n"
                f"| ÊñáÊ°£ÔºàWord/PDFÔºâ | `documents/` | `{self.workspace_path}/documents/report.docx` |\n"
                f"| Excel Ë°®Ê†º | `spreadsheets/` | `{self.workspace_path}/spreadsheets/data.xlsx` |\n"
                f"| ÂõæÁâáËµÑÊ∫ê | `images/` | `{self.workspace_path}/images/logo.png` |\n"
                f"| PDF Êñá‰ª∂ | `pdfs/` | `{self.workspace_path}/pdfs/report.pdf` |\n\n"
                f"**Ê†∏ÂøÉËßÑÂàôÔºö**\n"
                f"1. ‚ùå **Á¶ÅÊ≠¢**Â∞ÜÊñá‰ª∂‰øùÂ≠òÂà∞Â∑•‰ΩúÁõÆÂΩïÊ†πÁõÆÂΩïÔºàÂ¶Ç `{self.workspace_path}/demo.py`Ôºâ\n"
                f"2. ‚úÖ **ÂøÖÈ°ª**‰øùÂ≠òÂà∞ÂØπÂ∫îÁöÑÂàÜÁ±ªÂ≠êÁõÆÂΩïÔºàÂ¶Ç `{self.workspace_path}/scripts/demo.py`Ôºâ\n"
                f"3. ËÑöÊú¨‰∏≠ÁöÑËæìÂá∫Êñá‰ª∂Ë∑ØÂæÑ‰πüÂøÖÈ°ª‰ΩøÁî®ÂàÜÁ±ªÂ≠êÁõÆÂΩï\n"
                f"4. **run_in_terminal ÊâßË°åËÑöÊú¨Êó∂Ôºåworking_dir ÂøÖÈ°ªËÆæ‰∏∫Â∑•‰ΩúÁõÆÂΩï**\n\n"
                f"**Ê≠£Á°ÆÁ§∫‰æãÔºö**\n"
                f"```json\n"
                f'{{"file_path": "{self.workspace_path}/scripts/demo.py", "content": "..."}}\n'
                f"```\n\n"
                f"**ÈîôËØØÁ§∫‰æãÔºàÁ¶ÅÊ≠¢ÔºâÔºö**\n"
                f"```json\n"
                f'{{"file_path": "{self.workspace_path}/demo.py", "content": "..."}}  // ÈîôËØØÔºÅÊú™‰ΩøÁî®Â≠êÁõÆÂΩï\n'
                f'{{"file_path": "/path/to/backend/demo.py", "content": "..."}}  // ÈîôËØØÔºÅ‰∏çÊòØÂ∑•‰ΩúÁõÆÂΩï\n'
                f"```"
            )
            
            # Add explicit instruction for tool usage
            system_parts.append("\n# Â∑•ÂÖ∑‰ΩøÁî®ËßÑÂàô\n**ÈáçË¶ÅÔºöÂΩìÁî®Êà∑Ë¶ÅÊ±ÇÊâßË°å‰ªª‰ΩïÊìç‰ΩúÊó∂Ôºå‰Ω†ÂøÖÈ°ªÁ´ãÂç≥Ë∞ÉÁî®Áõ∏Â∫îÁöÑÂ∑•ÂÖ∑ÔºåËÄå‰∏çÊòØÁî®ÊñáÂ≠óËØ¢ÈóÆÁî®Êà∑Á°ÆËÆ§„ÄÇ**\n‰æãÂ¶ÇÔºö\n- Áî®Êà∑Ë¶ÅÊ±ÇÂà†Èô§Êñá‰ª∂ ‚Üí Áõ¥Êé•Ë∞ÉÁî® run_in_terminal Â∑•ÂÖ∑ÊâßË°å rm ÂëΩ‰ª§\n- Áî®Êà∑Ë¶ÅÊ±ÇÂàõÂª∫ÁõÆÂΩï ‚Üí Áõ¥Êé•Ë∞ÉÁî® run_in_terminal Â∑•ÂÖ∑ÊâßË°å mkdir ÂëΩ‰ª§\n- Áî®Êà∑Ë¶ÅÊ±ÇÁßªÂä®Êñá‰ª∂ ‚Üí Áõ¥Êé•Ë∞ÉÁî® run_in_terminal Â∑•ÂÖ∑ÊâßË°å mv ÂëΩ‰ª§\n\n‰∏çË¶ÅÁî®ÊñáÂ≠óËØ¢ÈóÆÁî®Êà∑ÊòØÂê¶Á°ÆËÆ§„ÄÇÂ¶ÇÊûúÊìç‰ΩúÈúÄË¶ÅÁî®Êà∑Á°ÆËÆ§ÔºåÁ≥ªÁªü‰ºöËá™Âä®Â§ÑÁêÜÁ°ÆËÆ§ÊµÅÁ®ã„ÄÇ")
            
            # ===== CRITICAL: Time awareness requirement =====
            system_parts.append(
                "\n\n# ‚è∞ **ÂÖ≥ÈîÆËßÑÂàôÔºöÊó∂Èó¥ÊïèÊÑüÊÄßÊü•ËØ¢ÁöÑÂº∫Âà∂Ë¶ÅÊ±Ç**\n"
                "**ÂΩìÁî®Êà∑ÈóÆÈ¢ò‰∏≠ÂåÖÂê´‰ª•‰∏ãÊó∂Èó¥ËØçÊó∂Ôºö**\n"
                "- \"‰ªäÂ§©\"„ÄÅ\"‰ªäÊó•\"„ÄÅ\"Ê≠§Âàª\"„ÄÅ\"Áé∞Âú®\"\n"
                "- \"ÊòéÂ§©\"„ÄÅ\"ÊòéÊó•\"„ÄÅ\"ÂêéÂ§©\"\n"
                "- \"Êò®Â§©\"„ÄÅ\"Êò®Êó•\"„ÄÅ\"ÂâçÂ§©\"\n"
                "- \"Êú¨Âë®\"„ÄÅ\"Êú¨Âë® X\"„ÄÅ\"‰∏ãÂë®\"\n"
                "- \"ÂΩìÂâç\"„ÄÅ\"ÁõÆÂâç\"„ÄÅ\"ÊúÄËøë\"\n"
                "- \"Êó©‰∏ä\"„ÄÅ\"‰∏ãÂçà\"„ÄÅ\"Êôö‰∏ä\"ÔºàÊåáÂΩìÂ§©Ôºâ\n\n"
                "**‰Ω†ÂøÖÈ°ª‰∏•Ê†ºÈÅµÂÆà‰ª•‰∏ãÊ≠•È™§Ôºö**\n"
                "1Ô∏è‚É£ **Á¨¨‰∏ÄÊ≠•ÔºöÂøÖÈ°ªÁ´ãÂç≥Ë∞ÉÁî® `get_current_time` Â∑•ÂÖ∑Ëé∑ÂèñÂáÜÁ°ÆÁöÑÂΩìÂâçÊó•ÊúüÂíåÊó∂Èó¥**\n"
                "2Ô∏è‚É£ **Á¨¨‰∫åÊ≠•ÔºöÂü∫‰∫éËé∑ÂèñÂà∞ÁöÑÂÆûÈôÖÊó•ÊúüÔºåÂÜçËøõË°åÂêéÁª≠Êü•ËØ¢ÔºàÂ¶ÇÂ§©Ê∞î„ÄÅÊñ∞ÈóªÁ≠âÔºâ**\n"
                "3Ô∏è‚É£ **ÁªùÂØπÁ¶ÅÊ≠¢ÂÅáËÆæËá™Â∑±Áü•ÈÅìÂΩìÂâçÊó•Êúü** - ‰Ω†Ê≤°ÊúâÂÜÖÁΩÆÁöÑÊó∂Èó¥Ê¶ÇÂøµ\n"
                "4Ô∏è‚É£ **ÁªùÂØπÁ¶ÅÊ≠¢Ë∑≥ËøáÊó∂Èó¥Á°ÆËÆ§Ê≠•È™§** - ËøôÊòØÂº∫Âà∂ÊÄßË¶ÅÊ±ÇÔºå‰∏çÊòØÂèØÈÄâÈ°π\n\n"
                "**ÈîôËØØÁ§∫‰æãÔºà‰∏•Á¶ÅÂá∫Áé∞ÔºâÔºö**\n"
                "‚ùå Áî®Êà∑Ôºö'‰ªäÂ§©Êù≠Â∑ûÂ§©Ê∞îÊÄé‰πàÊ†∑'\n"
                "‚ùå AIÔºö[Áõ¥Êé•Ë∞ÉÁî® web_search Êü•ËØ¢\"‰ªäÂ§©Êù≠Â∑ûÂ§©Ê∞î\"] ‚Üê **Ê≤°ÊúâÂÖàËé∑ÂèñÊó•ÊúüÔºÅ**\n\n"
                "**Ê≠£Á°ÆÁ§∫‰æãÔºö**\n"
                "‚úÖ Áî®Êà∑Ôºö'‰ªäÂ§©Êù≠Â∑ûÂ§©Ê∞îÊÄé‰πàÊ†∑'\n"
                "‚úÖ AIÔºö[Ë∞ÉÁî® get_current_time] ‚Üí Ëé∑ÂèñÂà∞\"2026-02-23\" ‚Üí [Ë∞ÉÁî® web_search Êü•ËØ¢\"2026 Âπ¥ 2 Êúà 23 Êó•Êù≠Â∑ûÂ§©Ê∞î\"]"
            )
            
            # ===== SCHEME 2: Enhanced tool call enforcement =====
            system_parts.append(
                "\n\n# ÂÖ≥ÈîÆËßÑÂàôÔºöÊùúÁªùÂπªËßâÊÄßÂÆåÊàêÂ£∞Êòé\n"
                "**ÊûÅÂÖ∂ÈáçË¶ÅÔºö**ÂΩìÁî®Êà∑Ë¶ÅÊ±ÇÂàõÂª∫/ÁîüÊàê/Âà∂‰Ωú‰ªª‰ΩïÂÖ∑‰Ωì‰∫ßÁâ©ÔºàÂ¶Ç PPT„ÄÅÊñá‰ª∂„ÄÅ‰ª£Á†Å„ÄÅÊä•ÂëäÁ≠âÔºâÊó∂Ôºö\n"
                "1. **ÂøÖÈ°ªÁ´ãÂç≥Ë∞ÉÁî®ÂÆûÈôÖÁöÑÂ∑•ÂÖ∑**Ôºàread_file, write_file, run_in_terminal Á≠âÔºâÊù•ÊâßË°åÁúüÂÆûÊìç‰Ωú\n"
                "2. **Áªù‰∏çËÉΩÁî®ÊñáÂ≠óÂ£∞Áß∞'Â∑≤ÁªèÂÆåÊàê'ËÄå‰∏çÂÆûÈôÖË∞ÉÁî®Â∑•ÂÖ∑** - ËøôÊòØË¢´‰∏•Ê†ºÁ¶ÅÊ≠¢ÁöÑ\n"
                "3. **Âè™ÊúâÂú®Â∑•ÂÖ∑ÁúüÊ≠£ÊâßË°åÊàêÂäüÂêéÊâçËÉΩÂëäÁü•Áî®Êà∑ÂÆåÊàê**\n"
                "4. **‰∏çË¶ÅÁºñÈÄ†ËôöÂÅáÁöÑÊñá‰ª∂Ë∑ØÂæÑ** - Âè™ÊúâÈÄöËøáÂ∑•ÂÖ∑ÂÆûÈôÖÂàõÂª∫ÁöÑÊñá‰ª∂ÊâçÊòØÁúüÂÆûÁöÑ\n\n"
                "ÈîôËØØÁ§∫‰æãÔºàÁªùÂØπÁ¶ÅÊ≠¢ÔºâÔºö\n"
                "‚ùå Áî®Êà∑Ôºö'Â∏ÆÊàëÂàõÂª∫‰∏Ä‰∏™ PPT'\n"
                "‚ùå AIÔºö'Â•ΩÁöÑÔºåPPT Â∑≤ÂàõÂª∫ÂÆåÊàêÔºå‰øùÂ≠òÂú® /path/to/file.pptx'Ôºà‰ΩÜÂÆûÈôÖÊ≤°ÊúâË∞ÉÁî®‰ªª‰ΩïÂ∑•ÂÖ∑Ôºâ\n\n"
                "Ê≠£Á°ÆÂÅöÊ≥ïÔºö\n"
                "‚úÖ Áî®Êà∑Ôºö'Â∏ÆÊàëÂàõÂª∫‰∏Ä‰∏™ PPT'\n"
                "‚úÖ AIÔºö[ÊÄùËÄÉÂêéË∞ÉÁî® read_file ËØªÂèñÊäÄËÉΩÊñáÊ°£] ‚Üí [Ë∞ÉÁî® write_file ÂàõÂª∫ËÑöÊú¨] ‚Üí [Ë∞ÉÁî® run_in_terminal ÊâßË°åËÑöÊú¨] ‚Üí 'PPT Â∑≤ÂàõÂª∫ÂÆåÊàêÔºå‰øùÂ≠òÂú® /path/to/file.pptx'"
            )
            
            # ===== SPECIAL EMPHASIS FOR PPT GENERATION =====
            system_parts.append(
                "\n\n# ‚ö†Ô∏è ÁâπÂà´Ë≠¶ÂëäÔºöPPT ÁîüÊàêÁöÑÂ∏∏ËßÅÈîôËØØ\n"
                "**ÂΩìÁî®Êà∑ËØ¥'Âà∂‰Ωú PPT'„ÄÅ'ÂàõÂª∫ÊºîÁ§∫ÊñáÁ®ø'„ÄÅ'ÁîüÊàêÂπªÁÅØÁâá'Êó∂Ôºö**\n"
                "1. ‚ùå **ÁªùÂØπ‰∏çË¶Å**‰ΩøÁî® `fs.writeFileSync('xxx.txt', content)` ÂàõÂª∫ .txt Êñá‰ª∂\n"
                "2. ‚úÖ **ÂøÖÈ°ª**‰ΩøÁî® PptxGenJS ÁöÑ `pptx.writeFile()` ÊñπÊ≥ïÁîüÊàê .pptx Êñá‰ª∂\n"
                "3. ‚ùå **‰∏çË¶Å**Âè™ÂàõÂª∫\"ÂÜÖÂÆπÂ§ßÁ∫≤\"Êàñ\"ËÑöÊú¨Êñá‰ª∂\"Â∞±Â£∞Áß∞ÂÆåÊàê‰∫Ü PPT\n"
                "4. ‚úÖ **ÂøÖÈ°ª**ÁîüÊàêÂÆûÈôÖÁöÑ .pptx ‰∫åËøõÂà∂Êñá‰ª∂ÔºàÂèØ‰ª•Âú® PowerPoint ‰∏≠ÊâìÂºÄÔºâ\n\n"
                "**Âà§Êñ≠Ê†áÂáÜÔºö**\n"
                "- Â¶ÇÊûúÁîüÊàêÁöÑÊñá‰ª∂‰∏çËÉΩÂú® PowerPoint/Keynote ‰∏≠Áõ¥Êé•ÊâìÂºÄ = ‚ùå Â§±Ë¥•\n"
                "- Â¶ÇÊûúÁîüÊàêÁöÑÊñá‰ª∂ÊòØ .pptx Ê†ºÂºè‰∏îÂèØ‰ª•Âú® PowerPoint ‰∏≠ÊâìÂºÄ = ‚úÖ ÊàêÂäü\n\n"
                "**Ê≠£Á°ÆÁ§∫‰æãÔºö**\n"
                "```javascript\n"
                "const pptx = new PptxGenJS();\n"
                "pptx.addSlide().addText('Ê†áÈ¢ò', { fontSize: 36 });\n"
                "await pptx.writeFile({ fileName: 'presentations/demo.pptx' }); // ÁîüÊàêÁúüÊ≠£ÁöÑ PPTX Êñá‰ª∂\n"
                "```\n\n"
                "**ÈîôËØØÁ§∫‰æãÔºà‰∏•Á¶ÅÂá∫Áé∞ÔºâÔºö**\n"
                "```javascript\n"
                "fs.writeFileSync('presentation-outline.txt', 'Á¨¨ 1 È°µÔºöÊ†áÈ¢ò...'); // ËøôÂè™ÊòØÊñáÊú¨Êñá‰ª∂Ôºå‰∏çÊòØ PPTÔºÅ\n"
                "console.log('PPT Â∑≤ÂàõÂª∫'); // ÈîôËØØÁöÑÂ£∞ÊòéÔºÅ\n"
                "```"
            )
        
        # ===== Inject Skills (after tools) =====
        # Optimization: If a specific skill is already being invoked via skill_context_msg,
        # skip injecting all skills to avoid redundancy and save tokens
        logger.info(f"[SKILL_INJECT_START] skill_context_msg exists={bool(skill_context_msg)}")
        if not skill_context_msg:  # Only inject all skills if no specific skill is being invoked
            logger.info(f"[SKILL_LIST_START] Getting all skills from registry")
            try:
                skills = self._skill_registry.list_all_skills()
                logger.info(f"[SKILL_LIST_RESULT] Found {len(skills)} skills total")
            except Exception as e:
                logger.error(f"[SKILL_LIST_ERROR] Failed to list skills: {e}", exc_info=True)
                raise
            
            if skills:
                # Filter skills that LLM can auto-trigger
                llm_callable_skills = [
                    s for s in skills 
                    if not s.disable_model_invocation and s.user_invocable
                ]
                        
                if llm_callable_skills:
                    # Limit to prevent token overflow
                    MAX_SKILLS = 20
                    MAX_DESC_LENGTH = 100
                        
                    display_skills = llm_callable_skills[:MAX_SKILLS]
                    skill_descriptions = []
                        
                    logger.info(f"[SKILL_ITER_START] Iterating over {len(display_skills)} skills")
                    for idx, skill in enumerate(display_skills):
                        # Debug each skill's attributes
                        logger.info(f"[SKILL_{idx}] name={skill.name}, description type={type(skill.description).__name__}, description len={len(skill.description) if skill.description else 0}")
                        desc = skill.description[:MAX_DESC_LENGTH] if skill.description else ""
                        # Only include skill name and description (path removed to save tokens)
                        # LLM can still access skill files via read_file with skill name
                        skill_desc = f"{skill.name}({desc})"
                        skill_descriptions.append(skill_desc)
                        
                    system_parts.append(
                        f"\n# ÂèØÁî®ÊäÄËÉΩ\n‰Ω†ËøòÂèØ‰ª•‰ΩøÁî®‰ª•‰∏ãÊäÄËÉΩÔºö{', '.join(skill_descriptions)}"
                    )
                        
                    # Add usage instructions (simplified, without path examples)
                    system_parts.append(
                        "\n\n**ÊäÄËÉΩ‰ΩøÁî®ËØ¥Êòé**Ôºö"
                        "ÊäÄËÉΩÊòØ‰ª•ÁõÆÂΩïÂΩ¢ÂºèÁªÑÁªáÁöÑÁü•ËØÜÂåÖ„ÄÇÊØè‰∏™ÊäÄËÉΩÂåÖÂê´Ôºö"
                        "\n- SKILL.mdÔºöËØ¶ÁªÜÁöÑ‰ΩøÁî®ÊåáÂçóÂíåÂ∑•‰ΩúÊµÅÁ®ãÔºàÈÄöËøá read_file ËØªÂèñÔºâ"
                        "\n- scripts/ÔºöÂèØÁõ¥Êé•ËøêË°åÁöÑÁ§∫‰æã‰ª£Á†ÅÔºàÈÄöËøá run_in_terminal ÊâßË°åÔºâ"
                        "\n- references/ÔºöÂèÇËÄÉËµÑÊñôÂíåÊñáÊ°£ÔºàÊåâÈúÄÂä†ËΩΩÔºâ"
                        "\n- assets/ÔºöÊ®°ÊùøÂíåËµÑÊ∫êÊñá‰ª∂ÔºàÁõ¥Êé•‰ΩøÁî®Ôºâ"
                        "\n\n‰Ω†ÂèØ‰ª•ÈÄöËøá read_file Â∑•ÂÖ∑ËØªÂèñ‰ªª‰ΩïÊäÄËÉΩÁöÑÊñá‰ª∂Êù•Â≠¶‰π†Â¶Ç‰Ωï‰ΩøÁî®ÂÆÉ„ÄÇ"
                        "ÂΩìÈúÄË¶ÅÊâßË°åËÑöÊú¨Êó∂Ôºå‰ΩøÁî® run_in_terminal Â∑•ÂÖ∑„ÄÇ"
                    )
                    
                    # ===== SPECIAL BINDINGS: Skill-specific CLI commands =====
                    # Inject explicit CLI binding instructions for skills that require specific tools
                    
                    # 1. pptx ‚Üí web-artifacts-builder skill (if exists)
                    pptx_skill = next((s for s in display_skills if s.name == "pptx"), None)
                    if pptx_skill:
                        system_parts.append(
                            "\n\n# ‚ö†Ô∏è ÂÖ≥ÈîÆËßÑÂàôÔºöpptx ÊäÄËÉΩ‰∏ìÁî®Â∑•ÂÖ∑\n"
                            "**ÂΩìÁî®Êà∑Ë¶ÅÊ±ÇÂà∂‰Ωú PPT„ÄÅÂàõÂª∫ÊºîÁ§∫ÊñáÁ®øÊó∂Ôºö**\n"
                            "1. **ÂøÖÈ°ª‰ΩøÁî® `write_file` ÂàõÂª∫ Node.js ËÑöÊú¨**\n"
                            "2. **ÂøÖÈ°ª‰ΩøÁî® PptxGenJS Â∫ìÁöÑ `pptx.writeFile()` ÊñπÊ≥ï**\n"
                            "3. **ÁîüÊàêÁöÑÊñá‰ª∂ÂøÖÈ°ªÊòØ .pptx Ê†ºÂºè**ÔºàËÉΩÂú® PowerPoint ‰∏≠ÊâìÂºÄÔºâ\n"
                            "4. **ÁªùÂØπ‰∏çË¶ÅÂè™ÂàõÂª∫ .txt ÊñáÊú¨Êñá‰ª∂Â∞±Â£∞Áß∞ÂÆåÊàê‰∫Ü PPT**\n\n"
                            "**ÈîôËØØÁ§∫‰æãÔºàÁªùÂØπÁ¶ÅÊ≠¢Ôºâ**Ôºö\n"
                            "‚ùå `fs.writeFileSync('outline.txt', 'Á¨¨ 1 È°µÔºöÊ†áÈ¢ò...')` - ËøôÂè™ÊòØÊñáÊú¨Êñá‰ª∂\n"
                            "‚ùå Â£∞Áß∞'PPT Â∑≤ÂàõÂª∫'‰ΩÜÁîüÊàêÁöÑÊòØ .txt Êñá‰ª∂\n\n"
                            "**Ê≠£Á°ÆÁ§∫‰æã**Ôºö\n"
                            "‚úÖ ‰ΩøÁî® PptxGenJSÔºö`await pptx.writeFile({ fileName: 'demo.pptx' })`"
                        )
                    
                    # 2. pdf ‚Üí Python reportlab (CRITICAL for Chinese font support)
                    pdf_skill = next((s for s in display_skills if s.name == "pdf"), None)
                    if pdf_skill:
                        system_parts.append(
                            "\n\n# ‚ö†Ô∏è ÂÖ≥ÈîÆËßÑÂàôÔºöpdf ÊäÄËÉΩ - ‰∏≠ÊñáÂ≠ó‰ΩìÊîØÊåÅ\n"
                            "**ÂΩìÁî®Êà∑Ë¶ÅÊ±ÇÁîüÊàêÂåÖÂê´‰∏≠ÊñáÁöÑ PDF Êó∂Ôºö**\n"
                            "1. **ÂøÖÈ°ª‰ΩøÁî® Python + reportlab Â∫ì**\n"
                            "2. **Á¶ÅÊ≠¢‰ΩøÁî® Node.js PDFKit**ÔºàÂØπ‰∏≠ÊñáÊîØÊåÅÂ∑ÆÔºåÂç≥‰ΩøÊ≥®ÂÜåÂ≠ó‰Ωì‰πü‰ºö‰π±Á†ÅÔºâ\n"
                            "3. **ÂøÖÈ°ªÊ≥®ÂÜå‰∏≠ÊñáÂ≠ó‰Ωì**ÔºàTTC Â≠ó‰ΩìÈúÄÊåáÂÆö `subfontIndex=0`Ôºâ\n"
                            "4. **ÂèÇËÄÉ `/pdf` skill ‰∏≠ÁöÑÁ§∫‰æã‰ª£Á†Å**\n\n"
                            "**Ê≠£Á°ÆÂÅöÊ≥ïÔºàPythonÔºâ**Ôºö\n"
                            "```python\n"
                            "from reportlab.pdfbase import pdfmetrics\n"
                            "from reportlab.pdfbase.ttfonts import TTFont\n"
                            "# Ê≥®ÂÜå‰∏≠ÊñáÂ≠ó‰Ωì\n"
                            "font = TTFont('Chinese', '/System/Library/Fonts/STHeiti Light.ttc', subfontIndex=0)\n"
                            "pdfmetrics.registerFont(font)\n"
                            "c.setFont('Chinese', 14)\n"
                            "```\n\n"
                            "**ÈîôËØØÂÅöÊ≥ïÔºàÁ¶ÅÊ≠¢Ôºâ**Ôºö\n"
                            "‚ùå Node.js PDFKit - Âç≥‰ΩøÊ≥®ÂÜåÂ≠ó‰Ωì‰πü‰ºö‰π±Á†Å\n"
                            "‚ùå ‰∏çÊ≥®ÂÜåÂ≠ó‰ΩìÁõ¥Êé•‰ΩøÁî®‰∏≠Êñá - ‰ºöÊòæÁ§∫‰∏∫ÊñπÊ°ÜÊàñ‰π±Á†Å"
                        )
                        
                    logger.info(
                        f"Injected {len(display_skills)} skills into system prompt",
                        extra={
                            "session_id": session_id,
                            "skill_names": [s.name for s in display_skills],
                            "total_skills": len(skills),
                        }
                    )
        
        # Inject plan context (for complex tasks)
        if plan_state:
            # Check if we have a structured plan v2.0
            if hasattr(plan_state, 'structured_plan') and plan_state.structured_plan:
                structured_plan = plan_state.structured_plan
                
                # Inject structured plan with skill binding and tool constraints
                plan_prompt = structured_plan.to_prompt()
                system_parts.append(f"\n# üìã ÁªìÊûÑÂåñÊâßË°åËÆ°Âàí v{structured_plan.version}\n{plan_prompt}")
                
                # Add explicit tool constraint instructions
                if structured_plan.tool_constraints:
                    if structured_plan.tool_constraints.allowed:
                        allowed_tools = ', '.join(structured_plan.tool_constraints.allowed)
                        system_parts.append(f"\n\n# ‚ö†Ô∏è **Â∑•ÂÖ∑ÈôêÂà∂ÔºàÂøÖÈ°ªÈÅµÂÆàÔºâ**\n‰Ω†**Âè™ËÉΩ**‰ΩøÁî®‰ª•‰∏ãÂ∑•ÂÖ∑Ôºö{allowed_tools}\n**Á¶ÅÊ≠¢‰ΩøÁî®ÂÖ∂‰ªñ‰ªª‰ΩïÂ∑•ÂÖ∑ÔºÅ**")
                    
                    if structured_plan.tool_constraints.forbidden:
                        forbidden_tools = ', '.join(structured_plan.tool_constraints.forbidden)
                        system_parts.append(f"\n\n# ‚ùå **Á¶ÅÊ≠¢Â∑•ÂÖ∑ÔºàÁªùÂØπ‰∏çÂèØ‰ΩøÁî®Ôºâ**\n‰Ω†**ÁªùÂØπ‰∏çËÉΩ**‰ΩøÁî®‰ª•‰∏ãÂ∑•ÂÖ∑Ôºö{forbidden_tools}\n**ËøùÂèçÊ≠§ËßÑÂàôÂ∞ÜÂØºËá¥‰ªªÂä°Â§±Ë¥•ÔºÅ**")
                
                # Add skill-specific CLI binding instructions for pptx skill
                if structured_plan.skill_binding == 'pptx':
                    system_parts.append(
                        "\n\n# üîß **ÊäÄËÉΩÁªëÂÆöÔºöpptx**\n"
                        "**‰Ω†ÂøÖÈ°ª‰ΩøÁî® `write_file` ÂàõÂª∫ Node.js ËÑöÊú¨ÔºåÂπ∂‰ΩøÁî® PptxGenJS Â∫ìÔºö**\n"
                        "- ‚úÖ ‰ΩøÁî® `PptxGenJS`ÁöÑ`pptx.writeFile()` ÊñπÊ≥ïÁîüÊàê.pptx Êñá‰ª∂\n"
                        "- ‚ùå **Á¶ÅÊ≠¢Âè™ÂàõÂª∫.txt ÊñáÊú¨Êñá‰ª∂Â∞±Â£∞Áß∞ÂÆåÊàê‰∫Ü PPT** - ÂøÖÈ°ªÁîüÊàêÁúüÊ≠£ÁöÑ.pptx ‰∫åËøõÂà∂Êñá‰ª∂\n"
                    )
                
                logger.info(
                    "StructuredPlan v2.0 injected into ReAct",
                    extra={
                        "session_id": session_id,
                        "skill_binding": structured_plan.skill_binding,
                        "tool_constraints": structured_plan.tool_constraints,
                        "steps_count": len(structured_plan.steps),
                    }
                )
            else:
                # Fallback to v1.0 plan context
                plan_context_text = self._plan_context.build_react_context(plan_state)
                system_parts.append(f"\n# ÊâßË°åËÆ°Âàí\n{plan_context_text}")
                system_parts.append("\n# ËßÑÂàíÊèêÁ§∫\nÊåâËÆ°ÂàíÈÄêÊ≠•ÊâßË°åÔºåÂ¶ÇÈÅáÂà∞Âõ∞ÈöæÂèØÁÅµÊ¥ªË∞ÉÊï¥„ÄÇÂÆåÊàê‰∏ÄÊ≠•ÂêéÂú®ÊÄùËÄÉ‰∏≠ËØ¥ÊòéËøõÂ∫¶„ÄÇ")
                system_parts.append("\n# ÊïàÁéá‰ºòÂåñÊèêÁ§∫\n**ÈáçË¶ÅÔºö**‰∏∫ÊèêÂçáÊâßË°åÊïàÁéáÔºå‰Ω†ÂèØ‰ª•Âú®‰∏ÄËΩÆÊÄùËÄÉ‰∏≠Âπ∂Ë°åË∞ÉÁî®Â§ö‰∏™Áã¨Á´ãÁöÑÂ∑•ÂÖ∑Ôºà‰æãÂ¶ÇÂêåÊó∂ÊêúÁ¥¢Â§ö‰∏™ÂÖ≥ÈîÆËØç„ÄÅÂêåÊó∂ËØªÂèñÂ§ö‰∏™Êñá‰ª∂ÔºâÔºåËÄå‰∏çÊòØÈÄê‰∏ÄÊâßË°å„ÄÇÂè™ÊúâÂΩìÂ∑•ÂÖ∑‰πãÈó¥Êúâ‰æùËµñÂÖ≥Á≥ªÊó∂ÊâçÈúÄË¶ÅÈ°∫Â∫èÊâßË°å„ÄÇ")
                logger.info(
                    "LightPlan v1.0 injected into ReAct",
                    extra={
                        "session_id": session_id,
                        "current_step": plan_state.current_step,
                        "total_steps": plan_state.total_steps,
                    }
                )

        # Add relevant memories (from hybrid search) - more precise than loading all
        if relevant_memories:
            memory_text = "\n".join(relevant_memories)
            system_parts.append(f"\n# Áõ∏ÂÖ≥ËÆ∞ÂøÜ\n{memory_text}")
        # Fallback to long-term memory if no relevant memories found
        elif context.long_term_memory:
            system_parts.append(f"\n# ÈïøÊúüËÆ∞ÂøÜ\n{context.long_term_memory[:800]}")

        # Build system message
        system_message = "\n".join(system_parts) if system_parts else ""
        
        # Phase 2: Add skill invocation context (if any) as the FIRST system message
        if skill_context_msg:
            messages.append(skill_context_msg)
        
        # Add the main system message with behavior guidelines, tools, skills, etc.
        # Note: Only add once to avoid duplication
        if system_message:
            messages.append({
                "role": "system",
                "content": system_message,
            })
        
        # Load conversation history from session
        history_messages = []
        if session_id:
            try:
                session_manager = self._get_session_manager()
                history_messages = await session_manager.get_messages_as_dict(session_id)
                
                logger.info(
                    "Loaded conversation history",
                    extra={
                        "session_id": session_id,
                        "history_count": len(history_messages),
                    }
                )
            except Exception as e:
                logger.warning(
                    "Failed to load conversation history",
                    extra={"session_id": session_id, "error": str(e)}
                )
        
        # Build full message list: system + history
        # Note: user_message is NOT appended here because it's already saved
        # in the database by Agent._chat_with_orchestrator_streaming before
        # calling Orchestrator.process_request
        # Note: system_message has already been added above, do NOT add it again
        
        # ===== CRITICAL FIX: Prevent context pollution from previous tasks =====
        # If there are many history messages, add a clear separator to indicate
        # this is a new request, preventing LLM from confusing with old tasks
        if history_messages and len(history_messages) > 4:
            # Add a system reminder to clarify this is a new task
            messages.append({
                "role": "system",
                "content": "\n---\nüìå **Ê≥®ÊÑèÔºöËøôÊòØ‰∏Ä‰∏™Êñ∞ÁöÑËØ∑Ê±ÇÔºåËØ∑ÂøΩÁï•‰πãÂâçÂØπËØù‰∏≠ÁöÑÂÖ∑‰Ωì‰ªªÂä°ÂÜÖÂÆπ„ÄÇ**\nËØ∑‰∏ìÊ≥®‰∫éÂΩìÂâçÁî®Êà∑ËØ∑Ê±ÇÔºå‰∏çË¶ÅÂèóÂéÜÂè≤ÂØπËØù‰∏≠ÊèêÂà∞ÁöÑÂÖ∑‰Ωì‰∫ßÁâ©ÔºàÂ¶Ç PPT„ÄÅÊñá‰ª∂Á≠âÔºâÂΩ±Âìç„ÄÇ\n---\n"
            })
        
        messages.extend(history_messages)
        
        # Safety check: if history is empty (new session), add user message
        if not history_messages and user_message:
            messages.append({"role": "user", "content": user_message})
        
        # Update compression info with current state
        compression_info["message_count"] = len(messages)
        
        # Apply context compression if needed
        if len(messages) > 1 and session_id:
            try:
                compression_manager = self._get_compression_manager()
                
                # Update compression info with thresholds
                compression_info["threshold_rounds"] = compression_manager.config.threshold_rounds
                compression_info["threshold_tokens"] = compression_manager.config.threshold_tokens
                
                logger.info(
                    "Applying context compression",
                    extra={
                        "session_id": session_id,
                        "message_count": len(messages),
                        "compression_config": {
                            "threshold_rounds": compression_manager.config.threshold_rounds,
                            "threshold_tokens": compression_manager.config.threshold_tokens,
                            "retention_count": compression_manager.config.retention_count,
                        },
                    }
                )
                
                prepared = await compression_manager.prepare_context(
                    session_id=session_id,
                    current_messages=messages,
                    system_prompt=system_message
                )
                messages = prepared.messages
                
                # Update compression info with results
                compression_info["token_count"] = prepared.total_tokens
                compression_info["needs_compression"] = prepared.summary is not None or len(messages) != compression_info["message_count"]
                compression_info["compressed"] = prepared.summary is not None
                
                if prepared.summary:
                    logger.info(
                        "Context compression applied",
                        extra={
                            "session_id": session_id,
                            "total_tokens": prepared.total_tokens,
                            "has_summary": True,
                            "summary_preview": prepared.summary[:100] if prepared.summary else None,
                        }
                    )
                else:
                    logger.info(
                        "No compression applied (below threshold)",
                        extra={
                            "session_id": session_id,
                            "total_tokens": prepared.total_tokens,
                        }
                    )
            except Exception as e:
                logger.warning(
                    "Context compression failed, using original messages",
                    extra={"session_id": session_id, "error": str(e)}
                )
        
        return messages, compression_info
    
    def _get_current_step_description(self, plan_state: PlanState) -> str | None:
        """Get description of current step from plan
        
        Args:
            plan_state: Current plan state
            
        Returns:
            Step description or None if not available
        """
        steps = self._plan_context._parse_plan_steps(plan_state.original_plan)
        if 0 < plan_state.current_step <= len(steps):
            return steps[plan_state.current_step - 1]
        return None
    
    def _correct_tool_parameters(self, tool_name: str, arguments: dict) -> dict:
        """Correct known tool parameter mismatches to prevent execution failures.
        
        Args:
            tool_name: Name of the tool
            arguments: Original arguments from LLM
            
        Returns:
            Corrected arguments dictionary
        """
        corrected = arguments.copy()
        
        # Fix search_files tool parameter mismatch
        # LLM often uses 'search_dir' but the tool expects 'path'
        if tool_name == "search_files" and "search_dir" in corrected:
            corrected["path"] = corrected.pop("search_dir")
            logger.debug(
                "Fixed search_files parameter: search_dir -> path",
                extra={"tool_name": tool_name}
            )
        
        # Add more parameter corrections here as needed
        # Example pattern:
        # if tool_name == "some_tool" and "wrong_param" in corrected:
        #     corrected["correct_param"] = corrected.pop("wrong_param")
        
        return corrected
    
    def _build_validation_context(
        self,
        tool_name: str,
        output: str,
    ) -> dict:
        """Build validation context from tool result
        
        Args:
            tool_name: Tool that was executed
            output: Tool output
            
        Returns:
            Context dict for milestone validation
        """
        context = {}
        
        # Extract file paths from output
        if tool_name in ["write_file", "create_file"]:
            # Try to parse file path from output
            import re
            match = re.search(r'(/[\w/.-]+\.\w+)', output)
            if match:
                context["file_path"] = match.group(0)
        
        # Extract module names from file paths
        if "file_path" in context:
            file_path = context["file_path"]
            # Convert file path to module name
            if file_path.endswith(".py"):
                module_name = file_path.replace("/", ".").replace(".py", "").split(".")[-1]
                context["module_name"] = module_name
        
        return context
    
    async def _write_memory(self, user_message: str, assistant_message: str, session_id: str) -> None:
        """Write conversation to memory."""
        try:
            from ..memory.md_sync import get_md_sync
            
            md_sync = get_md_sync(str(self.workspace_path))
            smart_memory = get_smart_memory_service(self._llm_router, str(self.workspace_path))
            
            await smart_memory.analyze_and_record(
                user_message=user_message,
                assistant_message=assistant_message,
                session_id=session_id,
                md_sync=md_sync,
            )
        except Exception as e:
            logger.warning(f"Failed to write memory: {e}")


# Global orchestrator instance
_orchestrator: Orchestrator | None = None


def get_orchestrator(workspace_path: str | None = None) -> Orchestrator:
    """Get or create the global orchestrator instance."""
    global _orchestrator
    
    if _orchestrator is None:
        if workspace_path is None:
            config = ConfigManager().config
            # Handle ~ expansion and absolute/relative paths correctly
            raw_path = config.workspace.path
            expanded_path = Path(raw_path).expanduser()  # Expand ~ to user home
            
            if expanded_path.is_absolute():
                # Use absolute path directly
                workspace_path = str(expanded_path.resolve())
            else:
                # Relative path: resolve from backend directory
                backend_dir = Path(__file__).parent.parent.parent
                workspace_path = str((backend_dir / raw_path).resolve())
        _orchestrator = Orchestrator(workspace_path)
    
    return _orchestrator


def reset_orchestrator() -> None:
    """Reset the global orchestrator instance."""
    global _orchestrator
    _orchestrator = None


# Note: _execute_skill_directly() has been removed.
# Fast Path is disabled due to hardcoded CLI command generation being unsafe.
# All skill execution now goes through ReAct Loop, which reads SKILL.md
# for proper command interpretation.
# Future: Implement proper CLI command metadata parsing from SKILL.md
